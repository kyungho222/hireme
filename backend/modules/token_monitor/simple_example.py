#!/usr/bin/env python3
"""
Token Monitor Module ê°„ë‹¨í•œ ì‚¬ìš© ì˜ˆì œ
ìƒˆ í”„ë¡œì íŠ¸ì—ì„œ ë°”ë¡œ ë³µì‚¬í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜ˆì œ
"""
import os
import sys
from pathlib import Path

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€ (í•„ìš”í•œ ê²½ìš°)
sys.path.append(str(Path(__file__).parent.parent))

import openai
from dotenv import load_dotenv
from modules.token_monitor import AutoTokenMonitor, TokenMonitor, TokenMonitorConfig

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Token Monitor ê°„ë‹¨í•œ ì‚¬ìš© ì˜ˆì œ")
    print("=" * 40)

    # 1. ëª¨ë‹ˆí„° ì´ˆê¸°í™”
    print("\n1ï¸âƒ£ ëª¨ë‹ˆí„° ì´ˆê¸°í™”")
    config = TokenMonitorConfig()
    monitor = TokenMonitor(config=config)
    auto_monitor = AutoTokenMonitor(token_monitor=monitor, config=config)
    print("   âœ… ì´ˆê¸°í™” ì™„ë£Œ")

    # 2. ìë™ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    print("\n2ï¸âƒ£ ìë™ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    auto_monitor.start_monitoring()
    print("   ğŸ” ëª¨ë‹ˆí„°ë§ í™œì„±í™”")

    # 3. OpenAI API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
    print("\n3ï¸âƒ£ OpenAI API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜")
    try:
        # ì‹¤ì œ API í˜¸ì¶œ (API í‚¤ê°€ ì„¤ì •ëœ ê²½ìš°)
        if os.getenv('OPENAI_API_KEY'):
            client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            response = client.chat.completions.create(
                model="gpt-5-mini",
                messages=[{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”! í† í° ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤."}],
                max_completion_tokens=100,
                temperature=1.0
            )

            # í† í° ì‚¬ìš©ëŸ‰ ìë™ ê¸°ë¡
            if hasattr(response, 'usage') and response.usage:
                usage = monitor.create_usage_record(
                    model="gpt-5-mini",
                    input_tokens=response.usage.prompt_tokens,
                    output_tokens=response.usage.completion_tokens,
                    endpoint="chat_completion",
                    project_id="example_project"
                )
                monitor.log_usage(usage)
                print(f"   ğŸ“ API í˜¸ì¶œ ì„±ê³µ: {usage.total_tokens} í† í° ì‚¬ìš©")
                print(f"   ğŸ’° ë¹„ìš©: ${usage.cost_estimate:.4f}")
        else:
            print("   âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
            # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
            usage = monitor.create_usage_record(
                model="gpt-5-mini",
                input_tokens=50,
                output_tokens=30,
                endpoint="simulation",
                project_id="example_project"
            )
            monitor.log_usage(usage)
            print(f"   ğŸ“ ì‹œë®¬ë ˆì´ì…˜: {usage.total_tokens} í† í° ì‚¬ìš©")

    except Exception as e:
        print(f"   âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    # 4. ì‚¬ìš©ëŸ‰ ì¡°íšŒ
    print("\n4ï¸âƒ£ ì‚¬ìš©ëŸ‰ ì¡°íšŒ")
    summary = monitor.get_usage_summary()
    daily = summary["daily"]
    monthly = summary["monthly"]

    print(f"   ğŸ“… ì˜¤ëŠ˜: {daily['total_tokens']} / {monitor.limits.daily_limit:,} í† í° ({daily.get('limit_usage_percent', 0):.1f}%)")
    print(f"   ğŸ“† ì´ë²ˆ ë‹¬: {monthly['total_tokens']} / {monitor.limits.monthly_limit:,} í† í° ({monthly.get('limit_usage_percent', 0):.1f}%)")
    print(f"   ğŸ’° ì˜¤ëŠ˜ ë¹„ìš©: ${daily['total_cost']:.4f}")
    print(f"   ğŸ” ìƒíƒœ: {summary['status']}")

    # 5. ìë™ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
    print("\n5ï¸âƒ£ ìë™ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    auto_monitor.stop_monitoring()
    print("   â¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")

    print("\nâœ… ì˜ˆì œ ì™„ë£Œ!")
    print("\nğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì •")
    print("   2. ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì´ ì½”ë“œ í†µí•©")
    print("   3. ìë™ ëª¨ë‹ˆí„°ë§ í™œì„±í™”")

if __name__ == "__main__":
    main()
