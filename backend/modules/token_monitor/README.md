# Token Monitor Module

ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì—ì„œë„ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ë…ë¦½ì ì¸ í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

- **ì‹¤ì‹œê°„ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì **: ëª¨ë“  OpenAI API í˜¸ì¶œ ìë™ ëª¨ë‹ˆí„°ë§
- **ë‹¤ì¤‘ í”„ë¡œì íŠ¸ ì§€ì›**: í”„ë¡œì íŠ¸ë³„ ë…ë¦½ì ì¸ ì‚¬ìš©ëŸ‰ ì¶”ì 
- **ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ**: í•œë„ ì´ˆê³¼ ì‹œ ì½˜ì†”/ì›¹í›… ì•Œë¦¼
- **ë°ì´í„° ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸°**: JSON, CSV, ZIP í˜•ì‹ ì§€ì›
- **ì„¤ì • ê´€ë¦¬**: í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì„¤ì • íŒŒì¼ë¡œ ìœ ì—°í•œ êµ¬ì„±
- **ë°ì´í„° ë³´ê´€**: ìë™ ì •ë¦¬ ë° ì••ì¶• ì˜µì…˜

## ğŸ“¦ ì„¤ì¹˜ ë° ì‚¬ìš©

### 1. ëª¨ë“ˆ ë³µì‚¬
```bash
# ì´ ëª¨ë“ˆì„ ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ë³µì‚¬
cp -r modules/token_monitor /path/to/your/project/
```

### 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install openai python-dotenv requests
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env íŒŒì¼)
```env
# OpenAI API í‚¤
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-5-mini

# í† í° í•œë„ ì„¤ì • (gpt-5-mini ê¸°ì¤€)
TOKEN_DAILY_LIMIT=2000000
TOKEN_MONTHLY_LIMIT=60000000
TOKEN_PER_MINUTE_LIMIT=200000
REQUESTS_PER_MINUTE_LIMIT=500

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
TOKEN_AUTO_MONITOR=true
TOKEN_MONITOR_INTERVAL=300
TOKEN_WARNING_THRESHOLD=0.8
TOKEN_ALERT_THRESHOLD=0.9

# ë°ì´í„° ì €ì¥ ê²½ë¡œ
TOKEN_MONITOR_DATA_DIR=data/token_usage

# ì „ì—­ ëª¨ë‹ˆí„°ë§ ì„¤ì • (ì—¬ëŸ¬ í”„ë¡œì íŠ¸ í†µí•© ì‹œ)
GLOBAL_TOKEN_DAILY_LIMIT=10000000
GLOBAL_TOKEN_MONTHLY_LIMIT=300000000
```

### 4. ê¸°ë³¸ ì‚¬ìš©ë²•
```python
# 1. ëª¨ë“ˆ import
from modules.token_monitor import TokenMonitor, TokenMonitorConfig, AutoTokenMonitor
from dotenv import load_dotenv
import openai

# 2. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# 3. ëª¨ë‹ˆí„° ìƒì„±
config = TokenMonitorConfig()
monitor = TokenMonitor(config=config)

# 4. OpenAI API í˜¸ì¶œ ì‹œ í† í° ì‚¬ìš©ëŸ‰ ìë™ ê¸°ë¡
client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

async def chat_with_monitoring(messages):
    response = await client.chat.completions.create(
        model="gpt-5-mini",
        messages=messages,
        max_completion_tokens=500
    )

    # í† í° ì‚¬ìš©ëŸ‰ ìë™ ê¸°ë¡
    if hasattr(response, 'usage') and response.usage:
        usage = monitor.create_usage_record(
            model="gpt-5-mini",
            input_tokens=response.usage.prompt_tokens,
            output_tokens=response.usage.completion_tokens,
            endpoint="chat_completion",
            project_id="my_project"
        )
        monitor.log_usage(usage)

    return response

# 5. ì‚¬ìš©ëŸ‰ ì¡°íšŒ
summary = monitor.get_usage_summary()
print(f"ì˜¤ëŠ˜ ì‚¬ìš©ëŸ‰: {summary['daily']['total_tokens']} í† í°")
print(f"ìƒíƒœ: {summary['status']}")
```

### 5. ìë™ ëª¨ë‹ˆí„°ë§
```python
# ìë™ ëª¨ë‹ˆí„°ë§ ì‹œì‘
auto_monitor = AutoTokenMonitor(token_monitor=monitor, config=config)
auto_monitor.start_monitoring()

# ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
auto_monitor.stop_monitoring()
```

### 6. FastAPIì™€ í•¨ê»˜ ì‚¬ìš©
```python
from fastapi import FastAPI
from modules.token_monitor import token_monitor, auto_monitor

app = FastAPI()

@app.on_event("startup")
async def startup_event():
    auto_monitor.start_monitoring()

@app.on_event("shutdown")
async def shutdown_event():
    auto_monitor.stop_monitoring()

@app.get("/token-usage")
async def get_token_usage():
    return token_monitor.get_usage_summary()
```

### 7. CLIë¡œ ì‚¬ìš©ëŸ‰ í™•ì¸
```bash
# Python ìŠ¤í¬ë¦½íŠ¸ë¡œ í™•ì¸
python -c "from modules.token_monitor import token_monitor; print(token_monitor.get_usage_summary())"

# ë˜ëŠ” ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
python quick_start.py
```

### 8. ì—¬ëŸ¬ í”„ë¡œì íŠ¸ í†µí•© ì‚¬ìš©ë²•
```python
from modules.token_monitor import TokenUsageAggregator, GlobalTokenMonitor, TokenSyncService

# ì—¬ëŸ¬ í”„ë¡œì íŠ¸ ë°ì´í„° í†µí•©
projects_data_dirs = [
    "project_a/data/token_usage",
    "project_b/data/token_usage",
    "project_c/data/token_usage"
]

aggregator = TokenUsageAggregator(projects_data_dirs)
daily_summary = aggregator.aggregate_daily_usage()
print(f"ì „ì²´ ì‚¬ìš©ëŸ‰: {daily_summary['total_tokens']:,} í† í°")

# ì „ì—­ ëª¨ë‹ˆí„°ë§
global_monitor = GlobalTokenMonitor()
global_summary = global_monitor.get_global_summary()

# ìë™ ë™ê¸°í™” ì„œë¹„ìŠ¤
sync_service = TokenSyncService(
    projects_config={
        "project_a": "project_a/data/token_usage",
        "project_b": "project_b/data/token_usage"
    },
    sync_interval=300,  # 5ë¶„ë§ˆë‹¤ ë™ê¸°í™”
    global_monitor=True
)
sync_service.start_sync()
```

## âš™ï¸ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```env
# ê¸°ë³¸ ì„¤ì •
TOKEN_MONITOR_DATA_DIR=data/token_usage
TOKEN_DAILY_LIMIT=2000000
TOKEN_MONTHLY_LIMIT=60000000
TOKEN_PER_MINUTE_LIMIT=200000
REQUESTS_PER_MINUTE_LIMIT=500

# ì•Œë¦¼ ì„¤ì •
TOKEN_WARNING_THRESHOLD=0.8
TOKEN_ALERT_THRESHOLD=0.9
TOKEN_AUTO_MONITOR=true
TOKEN_MONITOR_INTERVAL=300
TOKEN_AUTO_REPORT=true
TOKEN_REPORT_THRESHOLD=0.1

# ì›¹í›… ì„¤ì •
TOKEN_WEBHOOK_URL=https://hooks.slack.com/your-webhook-url

# ë¡œê¹… ì„¤ì •
TOKEN_ENABLE_FILE_LOGGING=true
TOKEN_LOG_LEVEL=INFO
TOKEN_RETENTION_DAYS=90
TOKEN_ENABLE_COMPRESSION=false
```

## ğŸ“Š API ì—”ë“œí¬ì¸íŠ¸

FastAPIì™€ í•¨ê»˜ ì‚¬ìš©í•  ë•Œ:

```python
from fastapi import FastAPI
from modules.token_monitor import token_monitor

app = FastAPI()

@app.get("/token-usage")
async def get_token_usage():
    return token_monitor.get_usage_summary()

@app.get("/token-status")
async def get_token_status():
    summary = token_monitor.get_usage_summary()
    return {
        "status": summary["status"],
        "daily_usage": summary["daily"]["limit_usage_percent"]
    }
```

## ğŸ“ ë°ì´í„° êµ¬ì¡°

```
data/token_usage/
â”œâ”€â”€ usage_2025-09-05.json      # ì¼ì¼ ì‚¬ìš©ëŸ‰
â”œâ”€â”€ monthly_2025-09.json       # ì›”ê°„ ì§‘ê³„
â”œâ”€â”€ project_my_project.json    # í”„ë¡œì íŠ¸ë³„ ì‚¬ìš©ëŸ‰
â”œâ”€â”€ logs/                      # ë¡œê·¸ íŒŒì¼
â”‚   â””â”€â”€ alerts_2025-09-05.log
â””â”€â”€ config.json               # ì„¤ì • íŒŒì¼
```

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### ë°ì´í„° ë‚´ë³´ë‚´ê¸°
```python
from modules.token_monitor.utils.export import TokenDataExporter

exporter = TokenDataExporter(monitor)
exporter.export_to_json("2025-09-01", "2025-09-05", "usage_report.json")
exporter.export_to_csv("2025-09-01", "2025-09-05", "usage_report.csv")
exporter.export_to_zip("2025-09-01", "2025-09-05", "usage_report.zip")
```

### ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
```python
from modules.token_monitor.utils.import_ import TokenDataImporter

importer = TokenDataImporter(monitor)
importer.import_from_json("usage_report.json", merge=True)
importer.import_from_csv("usage_report.csv", merge=True)
```

### ì„¤ì • ê´€ë¦¬
```python
# ì„¤ì • ì €ì¥
config.save_to_file("my_config.json")

# ì„¤ì • ë¡œë“œ
config = TokenMonitorConfig.load_from_file("my_config.json")

# í™˜ê²½ë³€ìˆ˜ì—ì„œ ì—…ë°ì´íŠ¸
config.update_from_env()
```

## ğŸ¯ ëª¨ë¸ë³„ í•œë„ (gpt-5-mini ê¸°ì¤€)

- **TPM (Tokens Per Minute)**: 200,000 í† í°/ë¶„
- **RPM (Requests Per Minute)**: 500 ìš”ì²­/ë¶„
- **TPD (Tokens Per Day)**: 2,000,000 í† í°/ì¼

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ìƒíƒœ

- **NORMAL**: ì •ìƒ ì‚¬ìš©ëŸ‰
- **WARNING**: ê²½ê³  ìˆ˜ì¤€ (80% ë„ë‹¬)
- **CRITICAL**: ìœ„í—˜ ìˆ˜ì¤€ (90% ë„ë‹¬)

## ğŸ”— í†µí•© ì˜ˆì œ

```python
# OpenAI ì„œë¹„ìŠ¤ì™€ í†µí•©
import openai
from modules.token_monitor import token_monitor

class MyOpenAIService:
    def __init__(self):
        self.client = openai.OpenAI(api_key="your-api-key")

    async def chat_completion(self, messages):
        response = await self.client.chat.completions.create(
            model="gpt-5-mini",
            messages=messages,
            max_completion_tokens=500
        )

        # í† í° ì‚¬ìš©ëŸ‰ ìë™ ê¸°ë¡
        if hasattr(response, 'usage') and response.usage:
            usage = token_monitor.create_usage_record(
                model="gpt-5-mini",
                input_tokens=response.usage.prompt_tokens,
                output_tokens=response.usage.completion_tokens,
                endpoint="chat_completion",
                project_id="my_project"
            )
            token_monitor.log_usage(usage)

        return response
```

## ğŸ“ ë¼ì´ì„ ìŠ¤

ì´ ëª¨ë“ˆì€ MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ¤ ê¸°ì—¬

ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê¸°ëŠ¥ ì œì•ˆì€ ì´ìŠˆë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”.
