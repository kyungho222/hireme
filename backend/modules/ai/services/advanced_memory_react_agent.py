"""
ê³ ê¸‰ ë©”ëª¨ë¦¬ ê´€ë¦¬ ReAct ì—ì´ì „íŠ¸
ì¥ê¸° ê¸°ì–µ, ë‹¨ê¸° ê¸°ì–µ, ì‘ì—… ê¸°ì–µì„ êµ¬ë¶„í•˜ì—¬ ê´€ë¦¬í•˜ëŠ” í–¥ìƒëœ ReAct ì—ì´ì „íŠ¸
"""

import asyncio
import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

from modules.ai.services.intelligent_react_agent import (
    ActionPlan,
    IntelligentReActAgent,
    ReasoningContext,
)
from modules.ai.services.react_agent_core import ReActMemory, ReActStep, ReActTool

logger = logging.getLogger(__name__)

class MemoryType(Enum):
    """ë©”ëª¨ë¦¬ íƒ€ì…"""
    WORKING = "working"      # ì‘ì—… ê¸°ì–µ (í˜„ì¬ ì‘ì—…)
    SHORT_TERM = "short_term"  # ë‹¨ê¸° ê¸°ì–µ (ìµœê·¼ ëŒ€í™”)
    LONG_TERM = "long_term"    # ì¥ê¸° ê¸°ì–µ (í•™ìŠµëœ ì§€ì‹)
    EPISODIC = "episodic"      # ê²½í—˜ ê¸°ì–µ (ê³¼ê±° ê²½í—˜)

@dataclass
class MemoryItem:
    """ë©”ëª¨ë¦¬ ì•„ì´í…œ"""
    content: str
    memory_type: MemoryType
    importance: float  # 0.0 ~ 1.0
    timestamp: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)
    access_count: int = 0
    last_accessed: Optional[datetime] = None

@dataclass
class TaskContext:
    """ì‘ì—… ì»¨í…ìŠ¤íŠ¸"""
    task_id: str
    goal: str
    start_time: datetime
    current_step: int
    status: str  # "active", "completed", "failed", "paused"
    progress: float  # 0.0 ~ 1.0
    sub_tasks: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)

class AdvancedMemoryManager:
    """ê³ ê¸‰ ë©”ëª¨ë¦¬ ê´€ë¦¬ì"""

    def __init__(self, max_working_items: int = 10, max_short_term_items: int = 50):
        self.working_memory: List[MemoryItem] = []
        self.short_term_memory: List[MemoryItem] = []
        self.long_term_memory: Dict[str, MemoryItem] = {}
        self.episodic_memory: List[MemoryItem] = []

        self.max_working_items = max_working_items
        self.max_short_term_items = max_short_term_items

        # ë©”ëª¨ë¦¬ ì••ì¶• ì„ê³„ê°’
        self.compression_threshold = 0.8

    def add_memory(self, content: str, memory_type: MemoryType, importance: float = 0.5, metadata: Dict[str, Any] = None):
        """ë©”ëª¨ë¦¬ ì¶”ê°€"""
        item = MemoryItem(
            content=content,
            memory_type=memory_type,
            importance=importance,
            timestamp=datetime.now(),
            metadata=metadata or {}
        )

        if memory_type == MemoryType.WORKING:
            self.working_memory.append(item)
            # ì‘ì—… ê¸°ì–µ í¬ê¸° ì œí•œ
            if len(self.working_memory) > self.max_working_items:
                self._compress_working_memory()

        elif memory_type == MemoryType.SHORT_TERM:
            self.short_term_memory.append(item)
            # ë‹¨ê¸° ê¸°ì–µ í¬ê¸° ì œí•œ
            if len(self.short_term_memory) > self.max_short_term_items:
                self._compress_short_term_memory()

        elif memory_type == MemoryType.LONG_TERM:
            # ì¥ê¸° ê¸°ì–µì€ í‚¤-ê°’ í˜•íƒœë¡œ ì €ì¥
            key = self._generate_memory_key(content)
            self.long_term_memory[key] = item

        elif memory_type == MemoryType.EPISODIC:
            self.episodic_memory.append(item)

        logger.info(f"[MemoryManager] {memory_type.value} ë©”ëª¨ë¦¬ ì¶”ê°€: {content[:50]}...")

    def retrieve_memory(self, query: str, memory_type: Optional[MemoryType] = None, limit: int = 5) -> List[MemoryItem]:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
        results = []

        if memory_type is None or memory_type == MemoryType.WORKING:
            results.extend(self._search_memory(self.working_memory, query, limit))

        if memory_type is None or memory_type == MemoryType.SHORT_TERM:
            results.extend(self._search_memory(self.short_term_memory, query, limit))

        if memory_type is None or memory_type == MemoryType.LONG_TERM:
            results.extend(self._search_memory(list(self.long_term_memory.values()), query, limit))

        if memory_type is None or memory_type == MemoryType.EPISODIC:
            results.extend(self._search_memory(self.episodic_memory, query, limit))

        # ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x.importance, reverse=True)
        return results[:limit]

    def update_memory_access(self, item: MemoryItem):
        """ë©”ëª¨ë¦¬ ì ‘ê·¼ ì •ë³´ ì—…ë°ì´íŠ¸"""
        item.access_count += 1
        item.last_accessed = datetime.now()

    def consolidate_memories(self):
        """ë©”ëª¨ë¦¬ í†µí•© (ë‹¨ê¸° â†’ ì¥ê¸°)"""
        # ì¤‘ìš”ë„ê°€ ë†’ì€ ë‹¨ê¸° ê¸°ì–µì„ ì¥ê¸° ê¸°ì–µìœ¼ë¡œ ì´ë™
        high_importance_items = [
            item for item in self.short_term_memory
            if item.importance > 0.7 and item.timestamp < datetime.now() - timedelta(hours=1)
        ]

        for item in high_importance_items:
            key = self._generate_memory_key(item.content)
            self.long_term_memory[key] = item
            self.short_term_memory.remove(item)
            logger.info(f"[MemoryManager] ë©”ëª¨ë¦¬ í†µí•©: {item.content[:50]}... â†’ ì¥ê¸° ê¸°ì–µ")

    def _search_memory(self, memory_list: List[MemoryItem], query: str, limit: int) -> List[MemoryItem]:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)"""
        query_lower = query.lower()
        results = []

        for item in memory_list:
            if query_lower in item.content.lower():
                results.append(item)
                self.update_memory_access(item)

        return results[:limit]

    def _generate_memory_key(self, content: str) -> str:
        """ë©”ëª¨ë¦¬ í‚¤ ìƒì„±"""
        # ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ í‚¤ ìƒì„±
        import hashlib
        return hashlib.md5(content.encode()).hexdigest()[:16]

    def _compress_working_memory(self):
        """ì‘ì—… ê¸°ì–µ ì••ì¶•"""
        # ì¤‘ìš”ë„ê°€ ë‚®ì€ í•­ëª© ì œê±°
        self.working_memory.sort(key=lambda x: x.importance, reverse=True)
        self.working_memory = self.working_memory[:self.max_working_items // 2]
        logger.info(f"[MemoryManager] ì‘ì—… ê¸°ì–µ ì••ì¶• ì™„ë£Œ")

    def _compress_short_term_memory(self):
        """ë‹¨ê¸° ê¸°ì–µ ì••ì¶•"""
        # ì˜¤ë˜ëœ í•­ëª©ê³¼ ì¤‘ìš”ë„ê°€ ë‚®ì€ í•­ëª© ì œê±°
        cutoff_time = datetime.now() - timedelta(hours=24)
        self.short_term_memory = [
            item for item in self.short_term_memory
            if item.timestamp > cutoff_time or item.importance > 0.6
        ]
        logger.info(f"[MemoryManager] ë‹¨ê¸° ê¸°ì–µ ì••ì¶• ì™„ë£Œ")

    def get_memory_summary(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ìš”ì•½ ì •ë³´"""
        return {
            "working_memory": len(self.working_memory),
            "short_term_memory": len(self.short_term_memory),
            "long_term_memory": len(self.long_term_memory),
            "episodic_memory": len(self.episodic_memory),
            "total_memories": (
                len(self.working_memory) +
                len(self.short_term_memory) +
                len(self.long_term_memory) +
                len(self.episodic_memory)
            )
        }

class AdvancedReActAgent(IntelligentReActAgent):
    """ê³ ê¸‰ ë©”ëª¨ë¦¬ ê´€ë¦¬ ReAct ì—ì´ì „íŠ¸"""

    def __init__(self, max_steps: int = 8):
        super().__init__(max_steps)

        # ê³ ê¸‰ ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.memory_manager = AdvancedMemoryManager()

        # ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
        self.current_task: Optional[TaskContext] = None
        self.task_history: List[TaskContext] = []

        # í•™ìŠµëœ íŒ¨í„´ ì €ì¥
        self.learned_patterns: Dict[str, Dict[str, Any]] = {}

    async def process_task(self, user_goal: str, initial_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """ê³ ê¸‰ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‘ì—… ì²˜ë¦¬"""
        logger.info(f"[AdvancedReActAgent] ì‘ì—… ì‹œì‘: {user_goal}")

        # ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        task_id = f"task_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.current_task = TaskContext(
            task_id=task_id,
            goal=user_goal,
            start_time=datetime.now(),
            current_step=0,
            status="active",
            progress=0.0
        )

        # ê´€ë ¨ ë©”ëª¨ë¦¬ ê²€ìƒ‰
        relevant_memories = self.memory_manager.retrieve_memory(user_goal, limit=3)
        if relevant_memories:
            logger.info(f"[AdvancedReActAgent] ê´€ë ¨ ë©”ëª¨ë¦¬ {len(relevant_memories)}ê°œ ë°œê²¬")
            for memory in relevant_memories:
                logger.info(f"  - {memory.memory_type.value}: {memory.content[:50]}...")

        # ì´ˆê¸°í™”
        self.memory = ReActMemory(max_steps=self.max_steps)
        self.memory.current_goal = user_goal
        self.memory.context = initial_context or {}

        # ì‘ì—… ê¸°ì–µì— ëª©í‘œ ì €ì¥
        self.memory_manager.add_memory(
            content=f"í˜„ì¬ ì‘ì—…: {user_goal}",
            memory_type=MemoryType.WORKING,
            importance=1.0,
            metadata={"task_id": task_id, "goal": user_goal}
        )

        try:
            # ê³ ê¸‰ ReAct ë£¨í”„ ì‹¤í–‰
            for step_num in range(self.max_steps):
                self.current_task.current_step = step_num
                self.current_task.progress = step_num / self.max_steps

                logger.info(f"[AdvancedReActAgent] ë‹¨ê³„ {step_num + 1}/{self.max_steps} ì‹œì‘")

                # 1. ë©”ëª¨ë¦¬ ê¸°ë°˜ ì§€ëŠ¥í˜• ì¶”ë¡ 
                reasoning_context = await self._memory_enhanced_reason(step_num)
                self.memory.add_step(ReActStep.REASONING, reasoning_context.reasoning)

                # 2. í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ ì•¡ì…˜ ê³„íš
                action_plan = await self._pattern_based_plan_action(reasoning_context)
                self.memory.add_step(ReActStep.ACTION, action_plan.reasoning, {
                    "tool": action_plan.tool_name,
                    "action": action_plan.action,
                    "parameters": action_plan.parameters,
                    "confidence": action_plan.confidence,
                    "pattern_used": action_plan.metadata.get("pattern_used", False)
                })

                # 3. ì•¡ì…˜ ì‹¤í–‰
                action_result = await self._execute_planned_action(action_plan)
                self.memory.add_step(ReActStep.ACTION, action_result["action"], action_result["metadata"])

                # 4. ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ ë° ê´€ì°°
                observation = await self._memory_enhanced_observe(action_result, action_plan)
                self.memory.add_step(ReActStep.OBSERVATION, observation["content"], observation["metadata"])

                # ëª©í‘œ ë‹¬ì„± í™•ì¸
                if self.memory.is_goal_achieved():
                    logger.info("[AdvancedReActAgent] ëª©í‘œ ë‹¬ì„± ê°ì§€")
                    self.current_task.status = "completed"
                    self.current_task.progress = 1.0
                    break

                # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ í™•ì¸
                if await self._should_terminate_early(observation):
                    logger.info("[AdvancedReActAgent] ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ë§Œì¡±")
                    self.current_task.status = "failed"
                    break

            # ì‘ì—… ì™„ë£Œ ì²˜ë¦¬
            if self.current_task.status == "active":
                self.current_task.status = "completed" if self.memory.is_goal_achieved() else "failed"

            self.task_history.append(self.current_task)

            # ë©”ëª¨ë¦¬ í†µí•©
            self.memory_manager.consolidate_memories()

            # ìµœì¢… ì‘ë‹µ ìƒì„±
            final_response = await self._generate_advanced_response()
            self.memory.add_step(ReActStep.FINAL, final_response)

            return {
                "success": True,
                "response": final_response,
                "steps": self.memory.steps,
                "goal_achieved": self.memory.is_goal_achieved(),
                "total_steps": len(self.memory.steps),
                "intelligence_metrics": await self._calculate_intelligence_metrics(),
                "memory_metrics": self.memory_manager.get_memory_summary(),
                "task_context": {
                    "task_id": self.current_task.task_id,
                    "status": self.current_task.status,
                    "progress": self.current_task.progress,
                    "duration": (datetime.now() - self.current_task.start_time).total_seconds()
                }
            }

        except Exception as e:
            logger.error(f"[AdvancedReActAgent] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            if self.current_task:
                self.current_task.status = "failed"
                self.task_history.append(self.current_task)

            return {
                "success": False,
                "error": str(e),
                "steps": self.memory.steps,
                "partial_response": self.memory.get_recent_context(),
                "memory_metrics": self.memory_manager.get_memory_summary()
            }

    async def _memory_enhanced_reason(self, step_num: int) -> ReasoningContext:
        """ë©”ëª¨ë¦¬ ê¸°ë°˜ ì§€ëŠ¥í˜• ì¶”ë¡ """
        goal = self.memory.current_goal
        previous_results = [step for step in self.memory.steps if step["step_type"] == ReActStep.OBSERVATION.value]

        # ê´€ë ¨ ë©”ëª¨ë¦¬ ê²€ìƒ‰
        relevant_memories = self.memory_manager.retrieve_memory(goal, limit=3)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤
        available_tools = [tool.name for tool in self.tools.values() if tool.can_handle(goal)]

        # ì˜ë„ ë¶„ì„
        user_intent = await self._analyze_user_intent(goal)

        # ì‹ ë¢°ë„ ê³„ì‚° (ë©”ëª¨ë¦¬ ì •ë³´ í¬í•¨)
        confidence = await self._calculate_confidence(goal, available_tools, previous_results)
        if relevant_memories:
            confidence += 0.1  # ê´€ë ¨ ë©”ëª¨ë¦¬ê°€ ìˆìœ¼ë©´ ì‹ ë¢°ë„ ì¦ê°€

        # ì¶”ë¡  ìƒì„± (ë©”ëª¨ë¦¬ ì •ë³´ í¬í•¨)
        if step_num == 0:
            reasoning = f"ì‚¬ìš©ì ëª©í‘œ ë¶„ì„: '{goal}' â†’ ì˜ë„: {user_intent}\n"
            reasoning += f"ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {', '.join(available_tools)}\n"
            reasoning += f"ì‹ ë¢°ë„: {confidence:.2f}\n"

            if relevant_memories:
                reasoning += f"ê´€ë ¨ ë©”ëª¨ë¦¬: {len(relevant_memories)}ê°œ ë°œê²¬\n"
                for memory in relevant_memories:
                    reasoning += f"  - {memory.memory_type.value}: {memory.content[:50]}...\n"

            reasoning += f"ë‹¤ìŒ ë‹¨ê³„: {available_tools[0] if available_tools else 'search'} ë„êµ¬ë¡œ ì‹œì‘"
        else:
            last_result = previous_results[-1] if previous_results else None
            if last_result and "ì˜¤ë¥˜" in last_result.get("content", ""):
                reasoning = f"ì´ì „ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ ë°œìƒ. ëŒ€ì•ˆ ì „ëµ ìˆ˜ë¦½:\n"
                reasoning += f"1. ë‹¤ë¥¸ ë„êµ¬ ì‹œë„: {available_tools[1] if len(available_tools) > 1 else 'search'}\n"
                reasoning += f"2. ë§¤ê°œë³€ìˆ˜ ì¡°ì •\n"
                reasoning += f"3. ë‹¨ê³„ë³„ ì ‘ê·¼"
            else:
                reasoning = f"ì´ì „ ê²°ê³¼ ë¶„ì„ ì™„ë£Œ. ë‹¤ìŒ ë‹¨ê³„ ê³„íš:\n"
                reasoning += f"ëª©í‘œ ë‹¬ì„± ì§„í–‰ë¥ : {len(previous_results)}/{self.max_steps}\n"
                reasoning += f"ì¶”ì²œ ë„êµ¬: {available_tools[0] if available_tools else 'search'}"

        return ReasoningContext(
            goal=goal,
            current_step=step_num,
            previous_results=previous_results,
            available_tools=available_tools,
            user_intent=user_intent,
            confidence=confidence,
            reasoning=reasoning
        )

    async def _pattern_based_plan_action(self, context: ReasoningContext) -> ActionPlan:
        """í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ ì•¡ì…˜ ê³„íš"""
        # ê¸°ì¡´ ê³„íš ìˆ˜ë¦½
        action_plan = await self._plan_action(context)

        # í•™ìŠµëœ íŒ¨í„´ í™•ì¸
        pattern_key = f"{context.user_intent}_{action_plan.tool_name}_{action_plan.action}"
        if pattern_key in self.learned_patterns:
            pattern = self.learned_patterns[pattern_key]
            # íŒ¨í„´ ê¸°ë°˜ ë§¤ê°œë³€ìˆ˜ ì¡°ì •
            action_plan.parameters.update(pattern.get("successful_parameters", {}))
            action_plan.confidence = min(action_plan.confidence + 0.1, 1.0)
            action_plan.metadata["pattern_used"] = True
            logger.info(f"[AdvancedReActAgent] í•™ìŠµëœ íŒ¨í„´ ì‚¬ìš©: {pattern_key}")

        return action_plan

    async def _memory_enhanced_observe(self, action_result: Dict[str, Any], plan: ActionPlan) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ê¸°ë°˜ ê´€ì°°"""
        # ê¸°ë³¸ ê´€ì°° ìˆ˜í–‰
        observation = await self._intelligent_observe(action_result, plan)

        # ë©”ëª¨ë¦¬ì— ê²°ê³¼ ì €ì¥
        tool_result = action_result.get("tool_result", "")
        is_success = "ì„±ê³µ" in tool_result or "ì™„ë£Œ" in tool_result

        # ì¤‘ìš”ë„ ê³„ì‚°
        importance = 0.7 if is_success else 0.3

        # ë‹¨ê¸° ê¸°ì–µì— ì €ì¥
        self.memory_manager.add_memory(
            content=f"{plan.tool_name} ë„êµ¬ë¡œ {plan.action} ì‹¤í–‰: {tool_result}",
            memory_type=MemoryType.SHORT_TERM,
            importance=importance,
            metadata={
                "tool": plan.tool_name,
                "action": plan.action,
                "success": is_success,
                "task_id": self.current_task.task_id if self.current_task else None
            }
        )

        # ì„±ê³µí•œ íŒ¨í„´ í•™ìŠµ
        if is_success:
            pattern_key = f"{self.memory.current_goal}_{plan.tool_name}_{plan.action}"
            self.learned_patterns[pattern_key] = {
                "successful_parameters": plan.parameters,
                "success_count": self.learned_patterns.get(pattern_key, {}).get("success_count", 0) + 1,
                "last_success": datetime.now().isoformat()
            }
            logger.info(f"[AdvancedReActAgent] ì„±ê³µ íŒ¨í„´ í•™ìŠµ: {pattern_key}")

        # ê²½í—˜ ê¸°ì–µì— ì €ì¥
        self.memory_manager.add_memory(
            content=f"ì‘ì—… '{self.memory.current_goal}'ì—ì„œ {plan.tool_name} ë„êµ¬ ì‚¬ìš©",
            memory_type=MemoryType.EPISODIC,
            importance=0.5,
            metadata={
                "task_goal": self.memory.current_goal,
                "tool_used": plan.tool_name,
                "success": is_success,
                "timestamp": datetime.now().isoformat()
            }
        )

        return observation

    async def _generate_advanced_response(self) -> str:
        """ê³ ê¸‰ ìµœì¢… ì‘ë‹µ ìƒì„±"""
        if self.memory.is_goal_achieved():
            response = f"âœ… '{self.memory.current_goal}' ëª©í‘œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!\n\n"
        else:
            response = f"âš ï¸ '{self.memory.current_goal}' ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ {len(self.memory.steps)}ë‹¨ê³„ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\n\n"

        # ì„±ëŠ¥ ë¶„ì„
        success_steps = [step for step in self.memory.steps if step["step_type"] == ReActStep.OBSERVATION.value and "ì„±ê³µ" in step.get("content", "")]
        response += f"ğŸ“Š ì„±ëŠ¥ ë¶„ì„:\n"
        response += f"- ì„±ê³µ ë‹¨ê³„: {len(success_steps)}ê°œ\n"
        response += f"- ì´ ë‹¨ê³„: {len(self.memory.steps)}ê°œ\n"
        response += f"- ì„±ê³µë¥ : {len(success_steps)/max(len(self.memory.steps), 1)*100:.1f}%\n\n"

        # ë©”ëª¨ë¦¬ ì •ë³´
        memory_summary = self.memory_manager.get_memory_summary()
        response += f"ğŸ§  ë©”ëª¨ë¦¬ ìƒíƒœ:\n"
        response += f"- ì‘ì—… ê¸°ì–µ: {memory_summary['working_memory']}ê°œ\n"
        response += f"- ë‹¨ê¸° ê¸°ì–µ: {memory_summary['short_term_memory']}ê°œ\n"
        response += f"- ì¥ê¸° ê¸°ì–µ: {memory_summary['long_term_memory']}ê°œ\n"
        response += f"- ê²½í—˜ ê¸°ì–µ: {memory_summary['episodic_memory']}ê°œ\n\n"

        # í•™ìŠµëœ íŒ¨í„´ ì •ë³´
        if self.learned_patterns:
            response += f"ğŸ“ í•™ìŠµëœ íŒ¨í„´: {len(self.learned_patterns)}ê°œ\n\n"

        # ì£¼ìš” ë‹¨ê³„ ìš”ì•½
        response += "ğŸ“‹ ìˆ˜í–‰ëœ ì£¼ìš” ë‹¨ê³„:\n"
        for i, step in enumerate(self.memory.steps, 1):
            if step["step_type"] == ReActStep.ACTION.value:
                response += f"{i}. {step['content']}\n"

        return response

# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
async def test_advanced_react_agent():
    """ê³ ê¸‰ ReAct ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""
    agent = AdvancedReActAgent(max_steps=6)

    test_goals = [
        "React ê°œë°œì ì±„ìš©ê³µê³ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”",
        "ì§€ì›ì ëª©ë¡ì„ ì¡°íšŒí•´ì£¼ì„¸ìš”",
        "ìµœì‹  AI ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”"
    ]

    for goal in test_goals:
        print(f"\n{'='*70}")
        print(f"ê³ ê¸‰ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ëª©í‘œ: {goal}")
        print(f"{'='*70}")

        result = await agent.process_task(goal)

        print(f"ì„±ê³µ: {result['success']}")
        print(f"ì‘ë‹µ: {result['response']}")
        print(f"ì´ ë‹¨ê³„: {result.get('total_steps', 0)}")

        if result.get('memory_metrics'):
            metrics = result['memory_metrics']
            print(f"ë©”ëª¨ë¦¬ ì§€í‘œ:")
            print(f"  - ì´ ë©”ëª¨ë¦¬: {metrics['total_memories']}ê°œ")
            print(f"  - ì‘ì—… ê¸°ì–µ: {metrics['working_memory']}ê°œ")
            print(f"  - ë‹¨ê¸° ê¸°ì–µ: {metrics['short_term_memory']}ê°œ")
            print(f"  - ì¥ê¸° ê¸°ì–µ: {metrics['long_term_memory']}ê°œ")
            print(f"  - ê²½í—˜ ê¸°ì–µ: {metrics['episodic_memory']}ê°œ")

        if result.get('task_context'):
            task = result['task_context']
            print(f"ì‘ì—… ì»¨í…ìŠ¤íŠ¸:")
            print(f"  - ìƒíƒœ: {task['status']}")
            print(f"  - ì§„í–‰ë¥ : {task['progress']*100:.1f}%")
            print(f"  - ì†Œìš” ì‹œê°„: {task['duration']:.2f}ì´ˆ")

        if result.get('intelligence_metrics'):
            metrics = result['intelligence_metrics']
            print(f"ì§€ëŠ¥ ì§€í‘œ:")
            print(f"  - ì„±ê³µë¥ : {metrics['success_rate']*100:.1f}%")
            print(f"  - íš¨ìœ¨ì„±: {metrics['efficiency']*100:.1f}%")
            print(f"  - ëª©í‘œ ë‹¬ì„±: {metrics['goal_achieved']}")

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_advanced_react_agent())
