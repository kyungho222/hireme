import re
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class ContextScore:
    """ë§¥ë½ ì ìˆ˜ ê²°ê³¼"""
    total_score: float
    category_scores: Dict[str, float]
    confidence: float
    is_recruitment: bool
    details: Dict[str, Any]

class FlexibleContextClassifier:
    """ìœ ì—°í•œ ë§¥ë½ ë¶„ë¥˜ê¸° - ì˜ë¯¸ì  ìœ ì‚¬ì„±ê³¼ ë¬¸ë§¥ ë¶„ì„ ê¸°ë°˜"""
    
    def __init__(self):
        # í•µì‹¬ ê°œë… ê·¸ë£¹ (ì˜ë¯¸ì  ìœ ì‚¬ì„± ê¸°ë°˜)
        self.concept_groups = {
            "recruitment_intent": {
                "primary": ["ì§€ì›", "ëª¨ì§‘", "ì±„ìš©", "êµ¬ì¸", "í™˜ì˜", "ì°¸ì—¬", "ê³µê³ ", "ë½‘ë‹¤", "ì„ ë°œ", "ì°¾ê³ ", "ëª¨ì§‘í•©ë‹ˆë‹¤", "ì°¾ê³  ìˆìŠµë‹ˆë‹¤"],
                "secondary": ["êµ¬í•˜ë‹¤", "ì°¾ë‹¤", "ëª¨ì‹œë‹¤", "ì´ˆëŒ€", "ì œì•ˆ", "ê¶Œìœ ", "ì „ë¬¸ê°€ë¥¼", "ë‹´ë‹¹ìë¥¼", "ê°œë°œìë¥¼", "ë””ìì´ë„ˆë¥¼", "ë§ˆì¼€í„°ë¥¼", "ê¸°íšìë¥¼", "ìš´ì˜ìë¥¼", "ë¶„ì„ê°€ë¥¼", "ë³´ì•ˆì„", "ì˜ì—…ì„", "ì¸ì‚¬ë¥¼", "í’ˆì§ˆì„"],
                "weight": 3.0
            },
            "application_process": {
                "primary": ["ì´ë ¥ì„œ", "ìê¸°ì†Œê°œì„œ", "í¬íŠ¸í´ë¦¬ì˜¤", "ì œì¶œ", "ì„œë¥˜", "ë©´ì ‘", "ì ‘ìˆ˜", "ì§€ì›ì„œ"],
                "secondary": ["ì œì¶œí•˜ë‹¤", "ì ‘ìˆ˜í•˜ë‹¤", "ë³´ë‚´ë‹¤", "ì˜¬ë¦¬ë‹¤", "ì²¨ë¶€", "ì²¨ë¶€íŒŒì¼", "í•„ìˆ˜", "í•„ìˆ˜ ì¡°ê±´", "ìš°ëŒ€", "ê²½í—˜ì´ ìˆìœ¼ì‹œë©´", "ëŠ¥ë ¥ì´ í•„ìš”", "ìê²©ì¦", "ë³´ìœ ì"],
                "weight": 2.0
            },
            "qualification_requirements": {
                "primary": ["ê²½í—˜", "ìê²©ì¦", "í•™ìœ„", "ê²½ë ¥", "ì‹ ì…", "ëŠ¥ë ¥", "ê¸°ìˆ ", "ì—­ëŸ‰"],
                "secondary": ["í•„ìš”í•˜ë‹¤", "ìš”êµ¬í•˜ë‹¤", "ê°€ì ¸ì•¼", "ê°–ì¶°ì•¼", "ì¤‘ìš”í•˜ë‹¤"],
                "weight": 1.0
            },
            "work_conditions": {
                "primary": ["ì—°ë´‰", "ì›”ê¸‰", "ì‹œê¸‰", "ê¸‰ì—¬", "ê·¼ë¬´ì§€", "ë³µë¦¬í›„ìƒ", "ì¬íƒ", "ì¶œê·¼"],
                "secondary": ["ì§€ê¸‰", "ì œê³µ", "ì§€ì›", "í™˜ê²½", "ì¡°ê±´", "í˜œíƒ"],
                "weight": 1.0
            },
            "attitude_qualities": {
                "primary": ["ì±…ì„ê°", "ì„±ì‹¤", "ë°°ìš°ë ¤ëŠ”", "ê¸ì •ì ", "ì ê·¹ì ", "ì—´ì •", "ë„ì „"],
                "secondary": ["ë§ˆì¸ë“œ", "ìì„¸", "íƒœë„", "ì •ì‹ ", "ì˜ì§€", "ì—´ì˜"],
                "weight": 1.0
            },
            "computer_skills": {
                "primary": ["ì»´í“¨í„°", "PC", "í”„ë¡œê·¸ë¨", "ì†Œí”„íŠ¸ì›¨ì–´", "ê¸°ìˆ ", "ìŠ¤í‚¬"],
                "secondary": ["í™œìš©", "ì‚¬ìš©", "ì¡°ì‘", "ë‹¤ë£°", "í•  ìˆ˜", "ëŠ¥ìˆ™"],
                "weight": 1.0
            }
        }
        
        # ë¬¸ë§¥ ê°•í™” íŒ¨í„´
        self.context_patterns = {
            "recruitment_structure": [
                r"([ê°€-í£]+)\s*(ì§€ì›ì|ëª¨ì§‘|ì±„ìš©|êµ¬ì¸)",
                r"([ê°€-í£]+)\s*(í™˜ì˜í•©ë‹ˆë‹¤|ëª¨ì‹­ë‹ˆë‹¤|ì°¾ê³  ìˆìŠµë‹ˆë‹¤)",
                r"([ê°€-í£]+)\s*(ì „ë¬¸ê°€|ë‹´ë‹¹ì)\s*(ì„|ë¥¼)\s*(ì°¾ê³ |ëª¨ì§‘)",
                r"(ì œì¶œ\s*ì„œë¥˜|ì§€ì›\s*ë°©ë²•|ì ‘ìˆ˜\s*ê¸°ê°„)",
                r"(ì—°ë´‰|ê¸‰ì—¬|ê·¼ë¬´ì¡°ê±´)\s*(ì€|ëŠ”)\s*([ê°€-í£]+)",
                r"(ê·¼ë¬´ì§€|ê·¼ë¬´ì¥ì†Œ)\s*(ì€|ëŠ”)\s*([ê°€-í£]+)"
            ],
            "qualification_structure": [
                r"([ê°€-í£]+)\s*(ëŠ¥ë ¥|ê¸°ìˆ |ê²½í—˜|ìê²©)\s*(ì„|ë¥¼)\s*([ê°€-í£]+)",
                r"([ê°€-í£]+)\s*(í•„ìš”|ìš”êµ¬|ì¤‘ìš”|ìš°ëŒ€)",
                r"([ê°€-í£]+)\s*(ê²½í—˜ì´|ëŠ¥ë ¥ì´)\s*(í•„ìš”|ìš°ëŒ€)",
                r"(ì‹ ì…|ê²½ë ¥)\s*(ì§€ì›ì|ì‚¬ì›|ì§ì›)",
                r"([ê°€-í£]+)\s*(ë“±|ë°)\s*([ê°€-í£]+)\s*(í™œìš©|ì‚¬ìš©)\s*(ê²½í—˜ì´|ëŠ¥ë ¥ì´)"
            ]
        }
        
        # ë¬¸ì¥ ê¸¸ì´ ë° ë³µì¡ì„± ê°€ì¤‘ì¹˜
        self.complexity_weights = {
            "length_threshold": 50,  # 50ì ì´ìƒ
            "sentence_count_threshold": 2,  # 2ë¬¸ì¥ ì´ìƒ
            "detail_bonus": 0.5  # ìƒì„¸í•œ ë‚´ìš© ë³´ë„ˆìŠ¤
        }
    
    def calculate_semantic_similarity(self, text: str, concept_group: Dict) -> float:
        """ì˜ë¯¸ì  ìœ ì‚¬ì„± ê³„ì‚°"""
        text_lower = text.lower()
        score = 0.0
        
        # 1ì°¨ í‚¤ì›Œë“œ ë§¤ì¹­ (ë†’ì€ ê°€ì¤‘ì¹˜)
        for keyword in concept_group["primary"]:
            if keyword in text_lower:
                score += 1.0
                # ì—°ì†ëœ í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤
                if len([k for k in concept_group["primary"] if k in text_lower]) > 1:
                    score += 0.3
        
        # 2ì°¨ í‚¤ì›Œë“œ ë§¤ì¹­ (ë‚®ì€ ê°€ì¤‘ì¹˜)
        for keyword in concept_group["secondary"]:
            if keyword in text_lower:
                score += 0.5
        
        # ë¬¸ë§¥ íŒ¨í„´ ë§¤ì¹­
        context_bonus = self._check_context_patterns(text, concept_group)
        score += context_bonus
        
        return score * concept_group["weight"]
    
    def _check_context_patterns(self, text: str, concept_group: Dict) -> float:
        """ë¬¸ë§¥ íŒ¨í„´ í™•ì¸"""
        bonus = 0.0
        
        # ì±„ìš© ì˜ë„ ê´€ë ¨ íŒ¨í„´
        if "recruitment_intent" in str(concept_group):
            for pattern in self.context_patterns["recruitment_structure"]:
                if re.search(pattern, text):
                    bonus += 0.5
        
        # ìê²© ìš”ê±´ ê´€ë ¨ íŒ¨í„´
        if "qualification_requirements" in str(concept_group):
            for pattern in self.context_patterns["qualification_structure"]:
                if re.search(pattern, text):
                    bonus += 0.3
        
        return bonus
    
    def calculate_complexity_bonus(self, text: str) -> float:
        """ë¬¸ì¥ ë³µì¡ì„± ë³´ë„ˆìŠ¤ ê³„ì‚°"""
        bonus = 0.0
        
        # ê¸¸ì´ ë³´ë„ˆìŠ¤
        if len(text) >= self.complexity_weights["length_threshold"]:
            bonus += self.complexity_weights["detail_bonus"]
        
        # ë¬¸ì¥ ìˆ˜ ë³´ë„ˆìŠ¤
        sentence_count = len(re.split(r'[.!?]+', text))
        if sentence_count >= self.complexity_weights["sentence_count_threshold"]:
            bonus += 0.3
        
        # ìƒì„¸í•œ ì„¤ëª… ë³´ë„ˆìŠ¤
        detail_indicators = ["êµ¬ì²´ì ìœ¼ë¡œ", "ìƒì„¸íˆ", "ìì„¸íˆ", "ì˜ˆë¥¼ ë“¤ì–´", "íŠ¹íˆ", "ë˜í•œ", "ê·¸ë¦¬ê³ "]
        detail_count = sum(1 for indicator in detail_indicators if indicator in text)
        bonus += detail_count * 0.2
        
        return bonus
    
    def classify_context(self, text: str) -> ContextScore:
        """ë§¥ë½ ë¶„ë¥˜ (ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤ìš©)"""
        return self.analyze_recruitment_context(text)
    
    def analyze_recruitment_context(self, text: str) -> ContextScore:
        """ì±„ìš© ë§¥ë½ ë¶„ì„"""
        logger.info(f"ğŸ” ë§¥ë½ ë¶„ì„ ì‹œì‘: {text[:50]}...")
        
        category_scores = {}
        total_score = 0.0
        
        # ê° ê°œë… ê·¸ë£¹ë³„ ì ìˆ˜ ê³„ì‚°
        for category, group in self.concept_groups.items():
            score = self.calculate_semantic_similarity(text, group)
            category_scores[category] = score
            total_score += score
            logger.info(f"ğŸ“Š {category}: {score:.2f}ì ")
        
        # ë³µì¡ì„± ë³´ë„ˆìŠ¤
        complexity_bonus = self.calculate_complexity_bonus(text)
        total_score += complexity_bonus
        category_scores["complexity_bonus"] = complexity_bonus
        
        # ì¡°í•© ê°€ì¤‘ì¹˜ ì ìš©
        combination_bonus = self._calculate_combination_bonus(category_scores)
        total_score += combination_bonus
        category_scores["combination_bonus"] = combination_bonus
        
        # ìµœì¢… ì ìˆ˜ ì¡°ì •
        final_score = self._adjust_final_score(total_score, category_scores)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = self._calculate_confidence(category_scores, text)
        
        # ì±„ìš© ì—¬ë¶€ íŒì •
        is_recruitment = final_score >= 5.0
        
        # ìƒì„¸ ì •ë³´
        details = {
            "text_length": len(text),
            "sentence_count": len(re.split(r'[.!?]+', text)),
            "key_indicators": self._extract_key_indicators(text),
            "score_breakdown": category_scores.copy()
        }
        
        result = ContextScore(
            total_score=final_score,
            category_scores=category_scores,
            confidence=confidence,
            is_recruitment=is_recruitment,
            details=details
        )
        
        logger.info(f"ğŸ¯ ìµœì¢… ê²°ê³¼: {final_score:.2f}ì  (ì±„ìš©: {is_recruitment}, ì‹ ë¢°ë„: {confidence:.2f})")
        
        return result
    
    def _calculate_combination_bonus(self, category_scores: Dict[str, float]) -> float:
        """ì¡°í•© ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        bonus = 0.0
        
        # ì§€ì› ì˜ë„ + ì œì¶œ ì ˆì°¨ ì¡°í•© (ê°•í•œ ì±„ìš© ì‹ í˜¸)
        if (category_scores.get("recruitment_intent", 0) > 0 and 
            category_scores.get("application_process", 0) > 0):
            bonus += 2.0
        
        # ì§€ì› ì˜ë„ + ìê²© ìš”ê±´ ì¡°í•©
        if (category_scores.get("recruitment_intent", 0) > 0 and 
            category_scores.get("qualification_requirements", 0) > 0):
            bonus += 1.0
        
        # ì§€ì› ì˜ë„ + ê·¼ë¬´ ì¡°ê±´ ì¡°í•©
        if (category_scores.get("recruitment_intent", 0) > 0 and 
            category_scores.get("work_conditions", 0) > 0):
            bonus += 1.0
        
        # ì§€ì› ì˜ë„ê°€ ì—†ìœ¼ë©´ í˜ë„í‹°
        if category_scores.get("recruitment_intent", 0) == 0:
            bonus -= 2.0
        
        return bonus
    
    def _adjust_final_score(self, total_score: float, category_scores: Dict[str, float]) -> float:
        """ìµœì¢… ì ìˆ˜ ì¡°ì •"""
        adjusted_score = total_score
        
        # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ í˜ë„í‹°
        if total_score < 3.0 and category_scores.get("complexity_bonus", 0) < 0.5:
            adjusted_score *= 0.8
        
        # ë„ˆë¬´ ë†’ì€ ì ìˆ˜ ì •ê·œí™”
        if adjusted_score > 15.0:
            adjusted_score = 15.0
        
        return adjusted_score
    
    def _calculate_confidence(self, category_scores: Dict[str, float], text: str) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.5  # ê¸°ë³¸ ì‹ ë¢°ë„
        
        # ì ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„
        total_score = sum(category_scores.values())
        if total_score >= 8.0:
            confidence += 0.3
        elif total_score >= 5.0:
            confidence += 0.2
        elif total_score >= 3.0:
            confidence += 0.1
        
        # ë¬¸ì¥ ê¸¸ì´ ê¸°ë°˜ ì‹ ë¢°ë„
        if len(text) >= 100:
            confidence += 0.1
        elif len(text) >= 50:
            confidence += 0.05
        
        # í‚¤ì›Œë“œ ë‹¤ì–‘ì„± ê¸°ë°˜ ì‹ ë¢°ë„
        non_zero_categories = sum(1 for score in category_scores.values() if score > 0)
        if non_zero_categories >= 3:
            confidence += 0.1
        elif non_zero_categories >= 2:
            confidence += 0.05
        
        return min(confidence, 1.0)
    
    def _extract_key_indicators(self, text: str) -> List[str]:
        """ì£¼ìš” ì§€í‘œ ì¶”ì¶œ"""
        indicators = []
        
        for category, group in self.concept_groups.items():
            for keyword in group["primary"]:
                if keyword in text.lower():
                    indicators.append(f"{category}: {keyword}")
        
        return indicators[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
context_classifier = FlexibleContextClassifier()

def classify_context(text: str) -> ContextScore:
    """ë§¥ë½ ë¶„ë¥˜ í•¨ìˆ˜ (ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤)"""
    return context_classifier.analyze_recruitment_context(text)

def is_recruitment_text(text: str, threshold: float = 5.0) -> Tuple[bool, float, Dict[str, Any]]:
    """ì±„ìš© í…ìŠ¤íŠ¸ ì—¬ë¶€ íŒë³„ (ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤)"""
    result = classify_context(text)
    return result.is_recruitment, result.total_score, result.details
