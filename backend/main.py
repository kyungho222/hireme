import codecs
import csv
import locale
import logging
import os
import sys
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import uvicorn

# .env íŒŒì¼ ë¡œë“œ (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
# try:
#     load_dotenv(dotenv_path=".env")
# except Exception:
#     pass  # .env íŒŒì¼ì´ ì—†ì–´ë„ ë¬´ì‹œ
from bson import ObjectId
from chatbot.routers.chatbot_router import router as chatbot_router
from dotenv import load_dotenv
from fastapi import Depends, FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse

# chatbot ë¼ìš°í„° ì¶”ê°€
try:
    from github import router as github_router
except ImportError:
    github_router = None
from modules.token_monitor import auto_monitor
from motor.motor_asyncio import AsyncIOMotorClient
from pydantic import BaseModel
from routers.applicants import get_mongo_service, get_similarity_service
from routers.applicants import router as applicants_router
from routers.dynamic_messages import router as dynamic_messages_router
from routers.integrated_ocr import router as integrated_ocr_router
from routers.job_posting import router as job_posting_router

# from routers.pdf_ocr import router as pdf_ocr_router
from routers.pick_chatbot import router as pick_chatbot_router
from routers.pick_chatbot_direct_registration import (
    router as pick_chatbot_direct_router,
)
from routers.sample_data import router as sample_data_router
from routers.token_monitor import router as token_monitor_router
from routers.upload import router as upload_router

# íšŒì‚¬ ì¸ì¬ìƒ ë¼ìš°í„° ì¶”ê°€
try:
    from routers.company_culture import router as company_culture_router
except ImportError:
    company_culture_router = None

# ëª¨ë“ˆí™”ëœ ë¼ìš°í„° ì¶”ê°€
try:
    from modules.resume.router import router as resume_router
except ImportError:
    resume_router = None

try:
    from modules.cover_letter.router import router as cover_letter_router
except ImportError:
    cover_letter_router = None

try:
    from modules.portfolio.router import router as portfolio_router
except ImportError:
    portfolio_router = None

try:
    from modules.hybrid.router import router as hybrid_router
except ImportError:
    hybrid_router = None

# AI ìœ ì‚¬ë„ ë¶„ì„ ëª¨ë“ˆí™”ëœ ë¼ìš°í„° ì¶”ê°€
try:
    from modules.api.routers.similarity_router import router as similarity_router
except ImportError:
    similarity_router = None


from modules.core.services.embedding_service import EmbeddingService
from modules.core.services.mongo_service import MongoService
from modules.core.services.similarity_service import SimilarityService
from modules.core.services.vector_service import VectorService

# Python í™˜ê²½ ì¸ì½”ë”© ì„¤ì •
# ì‹œìŠ¤í…œ ê¸°ë³¸ ì¸ì½”ë”©ì„ UTF-8ë¡œ ì„¤ì •
if sys.platform.startswith('win'):
    # Windows í™˜ê²½ì—ì„œ UTF-8 ê°•ì œ ì„¤ì •
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    # ì½˜ì†” ì¶œë ¥ ì¸ì½”ë”© ì„¤ì •
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())

# Lifespan ì´ë²¤íŠ¸ ê´€ë¦¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await init_services()

    # ìë™ í† í° ëª¨ë‹ˆí„°ë§ ì‹œì‘
    if os.getenv("TOKEN_AUTO_MONITOR", "true").lower() == "true":
        auto_monitor.start_monitoring()
        print("ğŸ” ìë™ í† í° ëª¨ë‹ˆí„°ë§ í™œì„±í™”")

    yield

    # Shutdown
    if auto_monitor.is_running:
        auto_monitor.stop_monitoring()
        print("â¹ï¸ ìë™ í† í° ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="AI ì±„ìš© ê´€ë¦¬ ì‹œìŠ¤í…œ API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í•œê¸€ ì¸ì½”ë”©ì„ ìœ„í•œ ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def add_charset_header(request, call_next):
    response = await call_next(request)

    # ëª¨ë“  JSON ì‘ë‹µì— UTF-8 ì¸ì½”ë”© ëª…ì‹œ
    if response.headers.get("content-type", "").startswith("application/json"):
        response.headers["content-type"] = "application/json; charset=utf-8"

    # í…ìŠ¤íŠ¸ ì‘ë‹µì—ë„ UTF-8 ì¸ì½”ë”© ëª…ì‹œ
    elif response.headers.get("content-type", "").startswith("text/"):
        if "charset" not in response.headers.get("content-type", ""):
            current_content_type = response.headers.get("content-type", "")
            response.headers["content-type"] = f"{current_content_type}; charset=utf-8"

    return response

# ë¼ìš°í„° ë“±ë¡
if github_router:
    app.include_router(github_router, prefix="/api", tags=["github"])
app.include_router(upload_router, tags=["upload"])
app.include_router(pick_chatbot_router, prefix="/api/pick-chatbot", tags=["pick-chatbot"])
app.include_router(pick_chatbot_direct_router, tags=["pick-chatbot-direct"])
app.include_router(dynamic_messages_router, tags=["dynamic-messages"])
app.include_router(integrated_ocr_router, prefix="/api/integrated-ocr", tags=["integrated-ocr"])
# app.include_router(pdf_ocr_router, prefix="/api/pdf-ocr", tags=["pdf_ocr"])
app.include_router(job_posting_router, tags=["job-postings"])
app.include_router(applicants_router, tags=["applicants"])
app.include_router(sample_data_router, prefix="/api/sample", tags=["sample-data"])
app.include_router(chatbot_router, prefix="/chatbot", tags=["chatbot"])
app.include_router(token_monitor_router, tags=["token-monitor"])

# íšŒì‚¬ ì¸ì¬ìƒ ë¼ìš°í„° ë“±ë¡
if company_culture_router:
    app.include_router(company_culture_router, tags=["company-culture"])

# ëª¨ë“ˆí™”ëœ ë¼ìš°í„° ë“±ë¡
if resume_router:
    app.include_router(resume_router, prefix="/api/resume", tags=["resume"])

if cover_letter_router:
    app.include_router(cover_letter_router, tags=["cover-letter"])

if portfolio_router:
    app.include_router(portfolio_router, prefix="/api/portfolio", tags=["portfolio"])

if hybrid_router:
    app.include_router(hybrid_router, prefix="/api/hybrid", tags=["hybrid"])

# AI ìœ ì‚¬ë„ ë¶„ì„ ëª¨ë“ˆí™”ëœ ë¼ìš°í„° ë“±ë¡
if similarity_router:
    app.include_router(similarity_router, tags=["similarity"])

# ì±„ìš©ê³µê³  ì—ì´ì „íŠ¸ ë¼ìš°í„° ë“±ë¡
try:
    from routers.job_posting_agent import router as job_posting_agent_router
    app.include_router(job_posting_agent_router, tags=["job-posting-agent"])
except ImportError:
    pass

# ë¦¬ì•¡íŠ¸ ì—ì´ì „íŠ¸ ë¼ìš°í„° ë“±ë¡
try:
    from routers.react_agent_router import router as react_agent_router
    app.include_router(react_agent_router, prefix="/api", tags=["react-agent"])
except ImportError:
    pass

# í–¥ìƒëœ ReAct ì—ì´ì „íŠ¸ ë¼ìš°í„° ë“±ë¡
try:
    from routers.react_agent_enhanced import router as react_agent_enhanced_router
    app.include_router(react_agent_enhanced_router, prefix="/api", tags=["react-agent-v2"])
except ImportError:
    pass

# ì±„ìš©ê³µê³  ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
try:
    from modules.job_posting.dynamic_templates import init_dynamic_template_manager
    from modules.job_posting.job_posting_agent import init_job_posting_agent

    # ì „ì—­ ë³€ìˆ˜ë¡œ ì´ˆê¸°í™” ìƒíƒœ ê´€ë¦¬
    agent_initialized = False

    async def init_services():
        global agent_initialized
        try:
            await init_dynamic_template_manager(client)
            await init_job_posting_agent(client, None)
            agent_initialized = True
        except Exception:
            pass

    # FastAPI startup ì´ë²¤íŠ¸ì—ì„œ ì´ˆê¸°í™” (lifespanìœ¼ë¡œ ëŒ€ì²´ë¨)
    # @app.on_event("startup")  # Deprecated - lifespanìœ¼ë¡œ ëŒ€ì²´
    # async def startup_event():
    #     await init_services()

except ImportError:
    pass


# MongoDB ì—°ê²° ìµœì í™”
MONGODB_URI = os.getenv("MONGODB_URI", "mongodb://localhost:27017/hireme")
client = AsyncIOMotorClient(
    MONGODB_URI,
    maxPoolSize=50,  # ìµœëŒ€ ì—°ê²° í’€ í¬ê¸°
    minPoolSize=10,  # ìµœì†Œ ì—°ê²° í’€ í¬ê¸°
    maxIdleTimeMS=30000,  # ìœ íœ´ ì—°ê²° íƒ€ì„ì•„ì›ƒ
    serverSelectionTimeoutMS=5000,  # ì„œë²„ ì„ íƒ íƒ€ì„ì•„ì›ƒ
    socketTimeoutMS=20000,  # ì†Œì¼“ íƒ€ì„ì•„ì›ƒ
    connectTimeoutMS=10000,  # ì—°ê²° íƒ€ì„ì•„ì›ƒ
    retryWrites=True  # ì“°ê¸° ì¬ì‹œë„
)
db = client.hireme

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "resume-vectors")

# í†µí•© ìµœì í™” ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬)
try:
    import asyncio

    from modules.core.services.optimization_service import initialize_optimization

    # í™˜ê²½ë³„ ìµœì í™” ì„¤ì •
    environment = os.getenv("ENVIRONMENT", "development")

    # ë¹„ë™ê¸° ì´ˆê¸°í™”ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
    async def init_optimization():
        await initialize_optimization(environment)

    # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰, ì—†ìœ¼ë©´ ìƒˆ ë£¨í”„ ìƒì„±
    try:
        loop = asyncio.get_running_loop()
        asyncio.create_task(init_optimization())
    except RuntimeError:
        # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆ ë£¨í”„ì—ì„œ ì‹¤í–‰
        asyncio.run(init_optimization())

except Exception:
    pass

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ì ìš©)
try:
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ì„¤ì • í™•ì¸
    fast_startup = os.getenv("FAST_STARTUP", "false").lower() == "true"
    lazy_loading = os.getenv("LAZY_LOADING_ENABLED", "false").lower() == "true"

    if fast_startup or lazy_loading:
        embedding_service = EmbeddingService(lazy_loading=True)
    else:
        embedding_service = EmbeddingService(lazy_loading=False)
except Exception:
    embedding_service = None

# VectorService ì„ íƒì  ì´ˆê¸°í™”
try:
    vector_service = VectorService(
        api_key=PINECONE_API_KEY or "dummy-key",
        index_name=PINECONE_INDEX_NAME
    )
except Exception:
    vector_service = None

# SimilarityService ì´ˆê¸°í™” (vector_serviceê°€ Noneì¼ ìˆ˜ ìˆìŒ)
try:
    similarity_service = SimilarityService(embedding_service, vector_service)
except Exception:
    similarity_service = None

# Pydantic ëª¨ë¸ë“¤
class User(BaseModel):
    id: Optional[str] = None
    username: str
    email: str
    role: str = "user"
    created_at: Optional[datetime] = None

class Resume(BaseModel):
    id: Optional[str] = None
    resume_id: Optional[str] = None
    name: str
    position: Optional[str] = ""
    department: Optional[str] = ""
    experience: Optional[str] = ""
    skills: Optional[str] = ""
    growthBackground: Optional[str] = ""
    motivation: Optional[str] = ""
    careerHistory: Optional[str] = ""
    analysisScore: int = 0
    analysisResult: str = ""
    status: str = "pending"
    created_at: Optional[datetime] = None

class ResumeChunk(BaseModel):
    id: Optional[str] = None
    resume_id: str
    chunk_id: str
    text: str
    start_pos: int
    end_pos: int
    chunk_index: int
    field_name: Optional[str] = None  # growthBackground, motivation, careerHistory
    metadata: Optional[Dict[str, Any]] = None
    vector_id: Optional[str] = None  # Pinecone ë²¡í„° ID
    created_at: Optional[datetime] = None

class Interview(BaseModel):
    id: Optional[str] = None
    user_id: str
    company: str
    position: str
    date: datetime
    status: str = "scheduled"
    created_at: Optional[datetime] = None

# ì´ˆê¸° ë°ì´í„° ë¡œë”© ìœ í‹¸ë¦¬í‹°: DBê°€ ë¹„ì–´ìˆìœ¼ë©´ ë£¨íŠ¸ CSVì—ì„œ ì„í¬íŠ¸
async def seed_applicants_from_csv_if_empty() -> None:
    try:
        total_documents = await db.applicants.count_documents({})
        if total_documents > 0:
            return

        project_root_csv_path = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "..", "hireme.applicants.csv")
        )
        if not os.path.exists(project_root_csv_path):
            return

        documents_to_insert = []
        with open(project_root_csv_path, mode="r", encoding="utf-8") as csv_file:
            reader = csv.DictReader(csv_file)
            for row in reader:
                document: Dict[str, Any] = {}

                # _id ì²˜ë¦¬: ê°€ëŠ¥í•˜ë©´ ObjectIdë¡œ ì €ì¥
                raw_id = row.get("_id")
                if raw_id and isinstance(raw_id, str) and len(raw_id) == 24:
                    try:
                        document["_id"] = ObjectId(raw_id)
                    except Exception:
                        document["_id"] = raw_id

                # resume_id ì²˜ë¦¬
                raw_resume_id = row.get("resume_id")
                if raw_resume_id and isinstance(raw_resume_id, str) and len(raw_resume_id) == 24:
                    try:
                        document["resume_id"] = ObjectId(raw_resume_id)
                    except Exception:
                        document["resume_id"] = raw_resume_id
                elif raw_resume_id:
                    document["resume_id"] = raw_resume_id

                # ë¬¸ìì—´ í•„ë“œë“¤: í•­ìƒ ë¬¸ìì—´ë¡œ ìºìŠ¤íŒ…
                string_fields = [
                    "name",
                    "position",
                    "department",
                    "experience",
                    "skills",
                    "growthBackground",
                    "motivation",
                    "careerHistory",
                    "analysisResult",
                    "status",
                ]
                for field_name in string_fields:
                    value = row.get(field_name, "")
                    document[field_name] = "" if value is None else str(value)

                # ìˆ«ì í•„ë“œ
                try:
                    document["analysisScore"] = int(row.get("analysisScore", "0") or 0)
                except Exception:
                    document["analysisScore"] = 0

                # created_at ì²˜ë¦¬
                created_at_raw = row.get("created_at")
                if created_at_raw:
                    try:
                        iso_candidate = created_at_raw.replace("Z", "+00:00")
                        document["created_at"] = datetime.fromisoformat(iso_candidate)
                    except Exception:
                        document["created_at"] = datetime.now()

                documents_to_insert.append(document)

        if documents_to_insert:
            await db.applicants.insert_many(documents_to_insert)
    except Exception:
        pass


def load_applicants_from_csv() -> List[Dict[str, Any]]:
    """DB ë¯¸ê°€ë™/ë¹„ì–´ìˆì„ ë•Œ CSVë¥¼ ì§ì ‘ ì½ì–´ ë°˜í™˜"""
    try:
        project_root_csv_path = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "..", "hireme.applicants.csv")
        )
        if not os.path.exists(project_root_csv_path):
            return []

        applicants: List[Dict[str, Any]] = []
        with open(project_root_csv_path, mode="r", encoding="utf-8") as csv_file:
            reader = csv.DictReader(csv_file)
            for row in reader:
                item: Dict[str, Any] = {}
                # id/_id
                raw_id = row.get("_id") or row.get("id")
                if raw_id:
                    item["id"] = str(raw_id)

                # ê¸°ë³¸ ë¬¸ìì—´ í•„ë“œ
                for field_name in [
                    "name",
                    "position",
                    "department",
                    "experience",
                    "skills",
                    "growthBackground",
                    "motivation",
                    "careerHistory",
                    "analysisResult",
                    "status",
                ]:
                    value = row.get(field_name, "")
                    item[field_name] = "" if value is None else str(value)

                # score
                try:
                    item["analysisScore"] = int(row.get("analysisScore", "0") or 0)
                except Exception:
                    item["analysisScore"] = 0

                # created_at
                created_at_raw = row.get("created_at")
                if created_at_raw:
                    try:
                        iso_candidate = created_at_raw.replace("Z", "+00:00")
                        item["created_at"] = datetime.fromisoformat(iso_candidate)
                    except Exception:
                        item["created_at"] = datetime.now()

                applicants.append(item)
        return applicants
    except Exception:
        return []

# API ë¼ìš°íŠ¸ë“¤
@app.get("/")
async def root():
    return {"message": "AI ì±„ìš© ê´€ë¦¬ ì‹œìŠ¤í…œ APIê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "message": "ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."}

# ì‚¬ìš©ì ê´€ë ¨ API
@app.get("/api/users", response_model=List[User])
async def get_users():
    users = await db.users.find().to_list(1000)
    # MongoDBì˜ _idë¥¼ idë¡œ ë³€í™˜
    for user in users:
        user["id"] = str(user["_id"])
        del user["_id"]
    return [User(**user) for user in users]

@app.post("/api/users", response_model=User)
async def create_user(user: User):
    user_dict = user.dict()
    user_dict["created_at"] = datetime.now()
    result = await db.users.insert_one(user_dict)
    user_dict["id"] = str(result.inserted_id)
    return User(**user_dict)

# ì´ë ¥ì„œ ê´€ë ¨ API
@app.get("/api/resumes", response_model=List[Resume])
async def get_resumes():
    resumes = await db.resumes.find().to_list(1000)
    # MongoDBì˜ _idë¥¼ idë¡œ ë³€í™˜
    for resume in resumes:
        resume["id"] = str(resume["_id"])
        del resume["_id"]
    return [Resume(**resume) for resume in resumes]

@app.post("/api/resumes", response_model=Resume)
async def create_resume(resume: Resume):
    resume_dict = resume.dict()
    resume_dict["created_at"] = datetime.now()
    result = await db.resumes.insert_one(resume_dict)
    resume_dict["id"] = str(result.inserted_id)
    return Resume(**resume_dict)

# ì§€ì›ìë³„ ì´ë ¥ì„œ ì¡°íšŒ API (ëª¨ë“  ì •ë³´ í¬í•¨)
@app.get("/api/applicants/{applicant_id}/resume")
async def get_applicant_resume(applicant_id: str):
    """ì§€ì›ìì˜ ì´ë ¥ì„œ ì •ë³´ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜´ (ë¶„ì„ ê²°ê³¼ í¬í•¨)"""
    try:
        # 1. ì§€ì›ì ì •ë³´ ì¡°íšŒ
        applicant = await db.applicants.find_one({"_id": ObjectId(applicant_id)})
        if not applicant:
            raise HTTPException(status_code=404, detail="ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. ì´ë ¥ì„œ ID í™•ì¸
        resume_id = applicant.get("resume_id")
        if not resume_id:
            raise HTTPException(status_code=404, detail="ì´ë ¥ì„œê°€ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # 3. ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ (resumes ì»¬ë ‰ì…˜ì—ì„œ)
        resume = await db.resumes.find_one({"_id": ObjectId(resume_id)})
        if not resume:
            # resumes ì»¬ë ‰ì…˜ì— ì—†ìœ¼ë©´ applicants ì»¬ë ‰ì…˜ì˜ ì´ë ¥ì„œ í•„ë“œë“¤ ì‚¬ìš©
            resume_data = {
                "name": applicant.get("name", ""),
                "position": applicant.get("position", ""),
                "department": applicant.get("department", ""),
                "experience": applicant.get("experience", ""),
                "skills": applicant.get("skills", ""),
                "growthBackground": applicant.get("growthBackground", ""),
                "motivation": applicant.get("motivation", ""),
                "careerHistory": applicant.get("careerHistory", ""),
                "analysisScore": applicant.get("analysisScore", 0),
                "analysisResult": applicant.get("analysisResult", ""),
                "status": applicant.get("status", "pending"),
                "created_at": applicant.get("created_at"),
                "extracted_text": applicant.get("extracted_text", ""),
                "file_metadata": applicant.get("file_metadata", {}),
                "source": "applicants_collection"
            }
        else:
            # resumes ì»¬ë ‰ì…˜ì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°
            resume_data = resume.copy()
            resume_data["source"] = "resumes_collection"

        # 4. _idë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        if "_id" in resume_data:
            resume_data["id"] = str(resume_data["_id"])
            del resume_data["_id"]

        # 5. ì§€ì›ì ê¸°ë³¸ ì •ë³´ë„ í¬í•¨
        resume_data["applicant_info"] = {
            "id": str(applicant["_id"]),
            "name": applicant.get("name", ""),
            "email": applicant.get("email", ""),
            "phone": applicant.get("phone", ""),
            "status": applicant.get("status", ""),
            "applied_at": applicant.get("applied_at"),
            "created_at": applicant.get("created_at")
        }

        # 6. AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ìˆëŠ” ê²½ìš°)
        try:
            from modules.ai.resume_analysis_service import ResumeAnalysisService

            # í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ì„¤ì • ì ìš©
            fast_startup = os.getenv("FAST_STARTUP", "false").lower() == "true"
            lazy_loading = os.getenv("LAZY_LOADING_ENABLED", "false").lower() == "true"
            analysis_service = ResumeAnalysisService(db, lazy_loading=(fast_startup or lazy_loading))
            analysis_result = await analysis_service.get_applicant_analysis(applicant_id)
            if analysis_result:
                resume_data["ai_analysis"] = analysis_result
        except Exception as e:
            print(f"[WARNING] AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            # AI ë¶„ì„ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ì´ë ¥ì„œ ì •ë³´ëŠ” ë°˜í™˜

        return {
            "success": True,
            "message": "ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ ì„±ê³µ",
            "data": resume_data
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë ¥ì„œ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

# AI ì´ë ¥ì„œ ë¶„ì„ API
@app.post("/api/ai-analysis/resume/analyze")
async def analyze_resume(request: dict):
    """ì´ë ¥ì„œ AI ë¶„ì„ ì‹¤í–‰"""
    try:
        from models.resume_analysis import ResumeAnalysisRequest
        from modules.ai.resume_analysis_service import ResumeAnalysisService

        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        applicant_id = request.get("applicant_id")
        analysis_type = request.get("analysis_type", "openai")
        force_reanalysis = request.get("force_reanalysis", False)
        weights = request.get("weights", {})  # ê°€ì¤‘ì¹˜ ì¶”ê°€

        if not applicant_id:
            raise HTTPException(status_code=400, detail="ì§€ì›ì IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ì ìš©)
        fast_startup = os.getenv("FAST_STARTUP", "false").lower() == "true"
        lazy_loading = os.getenv("LAZY_LOADING_ENABLED", "false").lower() == "true"
        analysis_service = ResumeAnalysisService(db, lazy_loading=(fast_startup or lazy_loading))

        # ë¶„ì„ ìš”ì²­ ìƒì„±
        analysis_request = ResumeAnalysisRequest(
            applicant_id=applicant_id,
            analysis_type=analysis_type,
            force_reanalysis=force_reanalysis,
            weights=weights  # ê°€ì¤‘ì¹˜ ì „ë‹¬
        )

        # ë¶„ì„ ì‹¤í–‰
        result = await analysis_service.analyze_resume(analysis_request)

        if result.success:
            return {
                "success": True,
                "message": result.message,
                "data": result.data,
                "analysis_id": result.analysis_id,
                "processing_time": result.processing_time
            }
        else:
            raise HTTPException(status_code=500, detail=result.message)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/ai-analysis/resume/batch-analyze")
async def batch_analyze_resumes(request: dict):
    """ì´ë ¥ì„œ ì¼ê´„ AI ë¶„ì„"""
    try:
        from models.resume_analysis import BatchAnalysisRequest
        from modules.ai.resume_analysis_service import ResumeAnalysisService

        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        applicant_ids = request.get("applicant_ids", [])
        analysis_type = request.get("analysis_type", "openai")

        if not applicant_ids:
            raise HTTPException(status_code=400, detail="ì§€ì›ì ID ë¦¬ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ì ìš©)
        fast_startup = os.getenv("FAST_STARTUP", "false").lower() == "true"
        lazy_loading = os.getenv("LAZY_LOADING_ENABLED", "false").lower() == "true"
        analysis_service = ResumeAnalysisService(db, lazy_loading=(fast_startup or lazy_loading))

        # ì¼ê´„ ë¶„ì„ ìš”ì²­ ìƒì„±
        batch_request = BatchAnalysisRequest(
            applicant_ids=applicant_ids,
            analysis_type=analysis_type
        )

        # ì¼ê´„ ë¶„ì„ ì‹¤í–‰
        result = await analysis_service.batch_analyze(batch_request)

        if result.success:
            return {
                "success": True,
                "message": result.message,
                "data": result.data,
                "processing_time": result.processing_time
            }
        else:
            raise HTTPException(status_code=500, detail=result.message)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/ai-analysis/resume/reanalyze")
async def reanalyze_resume(request: dict):
    """ì´ë ¥ì„œ ì¬ë¶„ì„"""
    try:
        from models.resume_analysis import ResumeAnalysisRequest
        from modules.ai.resume_analysis_service import ResumeAnalysisService

        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        applicant_id = request.get("applicant_id")
        analysis_type = request.get("analysis_type", "openai")

        if not applicant_id:
            raise HTTPException(status_code=400, detail="ì§€ì›ì IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ì ìš©)
        fast_startup = os.getenv("FAST_STARTUP", "false").lower() == "true"
        lazy_loading = os.getenv("LAZY_LOADING_ENABLED", "false").lower() == "true"
        analysis_service = ResumeAnalysisService(db, lazy_loading=(fast_startup or lazy_loading))

        # ì¬ë¶„ì„ ìš”ì²­ ìƒì„±
        analysis_request = ResumeAnalysisRequest(
            applicant_id=applicant_id,
            analysis_type=analysis_type,
            force_reanalysis=True
        )

        # ì¬ë¶„ì„ ì‹¤í–‰
        result = await analysis_service.reanalyze_resume(analysis_request)

        if result.success:
            return {
                "success": True,
                "message": result.message,
                "data": result.data,
                "analysis_id": result.analysis_id,
                "processing_time": result.processing_time
            }
        else:
            raise HTTPException(status_code=500, detail=result.message)

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ì¬ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì¬ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/api/ai-analysis/resume/analysis-status")
async def get_analysis_status():
    """AI ë¶„ì„ ìƒíƒœ ì¡°íšŒ"""
    try:
        from modules.ai.resume_analysis_service import ResumeAnalysisService

        # ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ì ìš©)
        fast_startup = os.getenv("FAST_STARTUP", "false").lower() == "true"
        lazy_loading = os.getenv("LAZY_LOADING_ENABLED", "false").lower() == "true"
        analysis_service = ResumeAnalysisService(db, lazy_loading=(fast_startup or lazy_loading))

        # ìƒíƒœ ì¡°íšŒ
        status = await analysis_service.get_analysis_status()

        if status.success:
            return {
                "success": True,
                "message": status.message,
                "data": status.data,
                "total_applicants": status.total_applicants,
                "analyzed_count": status.analyzed_count,
                "pending_count": status.pending_count,
                "failed_count": status.failed_count,
                "progress_percentage": status.progress_percentage
            }
        else:
            raise HTTPException(status_code=500, detail=status.message)

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ë¶„ì„ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ìƒíƒœ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/api/ai-analysis/resume/{applicant_id}")
async def get_applicant_analysis(applicant_id: str):
    """ì§€ì›ìë³„ AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    try:
        from modules.ai.resume_analysis_service import ResumeAnalysisService

        # ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (í•˜ì´ë¸Œë¦¬ë“œ ë¡œë”© ì ìš©)
        fast_startup = os.getenv("FAST_STARTUP", "false").lower() == "true"
        lazy_loading = os.getenv("LAZY_LOADING_ENABLED", "false").lower() == "true"
        analysis_service = ResumeAnalysisService(db, lazy_loading=(fast_startup or lazy_loading))

        # ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        analysis_result = await analysis_service.get_applicant_analysis(applicant_id)

        if analysis_result:
            return {
                "success": True,
                "message": "AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì„±ê³µ",
                "data": analysis_result
            }
        else:
            raise HTTPException(status_code=404, detail="AI ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ì§€ì›ìë³„ í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ API
@app.get("/api/portfolios/applicant/{applicant_id}")
async def get_applicant_portfolio(applicant_id: str):
    """ì§€ì›ìì˜ í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜´"""
    try:
        # 1. ì§€ì›ì ì •ë³´ ì¡°íšŒ
        applicant = await db.applicants.find_one({"_id": ObjectId(applicant_id)})
        if not applicant:
            raise HTTPException(status_code=404, detail="ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. í¬íŠ¸í´ë¦¬ì˜¤ URL í™•ì¸
        portfolio_url = applicant.get("portfolio_url")
        if not portfolio_url:
            return {
                "success": False,
                "message": "í¬íŠ¸í´ë¦¬ì˜¤ URLì´ ì—†ìŠµë‹ˆë‹¤.",
                "data": None
            }

        # 3. GitHub URLì¸ ê²½ìš° GitHub APIë¡œ ìš”ì•½ ìƒì„±
        if "github.com" in portfolio_url:
            try:
                # GitHub API í˜¸ì¶œ
                github_response = await fetch_github_summary(portfolio_url)
                if github_response.get("success"):
                    return {
                        "success": True,
                        "message": "í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ ì„±ê³µ",
                        "data": {
                            "portfolio_url": portfolio_url,
                            "github_summary": github_response.get("data"),
                            "applicant_info": {
                                "id": str(applicant.get("_id")),
                                "name": applicant.get("name", ""),
                                "email": applicant.get("email", ""),
                                "position": applicant.get("position", "")
                            }
                        }
                    }
                else:
                    return {
                        "success": False,
                        "message": f"GitHub ë¶„ì„ ì‹¤íŒ¨: {github_response.get('message')}",
                        "data": {
                            "portfolio_url": portfolio_url,
                            "applicant_info": {
                                "id": str(applicant.get("_id")),
                                "name": applicant.get("name", ""),
                                "email": applicant.get("email", ""),
                                "position": applicant.get("position", "")
                            }
                        }
                    }
            except Exception as e:
                return {
                    "success": False,
                    "message": f"GitHub ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                    "data": {
                        "portfolio_url": portfolio_url,
                        "applicant_info": {
                            "id": str(applicant.get("_id")),
                            "name": applicant.get("name", ""),
                            "email": applicant.get("email", ""),
                            "position": applicant.get("position", "")
                        }
                    }
                }
        else:
            # GitHubê°€ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ ì •ë³´ë§Œ ë°˜í™˜
            return {
                "success": True,
                "message": "í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ ì„±ê³µ (GitHubê°€ ì•„ë‹˜)",
                "data": {
                    "portfolio_url": portfolio_url,
                    "applicant_info": {
                        "id": str(applicant.get("_id")),
                        "name": applicant.get("name", ""),
                        "email": applicant.get("email", ""),
                        "position": applicant.get("position", "")
                    }
                }
            }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

# GitHub ìš”ì•½ ìƒì„± í•¨ìˆ˜
async def fetch_github_summary(github_url: str):
    """GitHub URLì—ì„œ ì‚¬ìš©ìëª…ì„ ì¶”ì¶œí•˜ê³  GitHub API í˜¸ì¶œ"""
    try:
        # GitHub URLì—ì„œ ì‚¬ìš©ìëª… ì¶”ì¶œ
        if "github.com/" in github_url:
            parts = github_url.split("github.com/")[1].split("/")
            username = parts[0]
        else:
            return {"success": False, "message": "ìœ íš¨í•˜ì§€ ì•Šì€ GitHub URL"}

        # ì‹¤ì œ GitHub API í˜¸ì¶œ
        try:
            import os

            import requests

            # GitHub API í† í° í™•ì¸
            github_token = os.getenv('GITHUB_TOKEN')
            headers = {}
            if github_token:
                headers['Authorization'] = f'token {github_token}'

            # GitHub ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            user_response = requests.get(f'https://api.github.com/users/{username}', headers=headers, timeout=10)

            if user_response.status_code == 200:
                user_data = user_response.json()

                # ì €ì¥ì†Œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                repos_response = requests.get(f'https://api.github.com/users/{username}/repos?per_page=10&sort=updated', headers=headers, timeout=10)
                repos_data = []
                if repos_response.status_code == 200:
                    repos_data = repos_response.json()

                # ì–¸ì–´ í†µê³„ ìˆ˜ì§‘
                languages = {}
                for repo in repos_data[:5]:  # ìµœê·¼ 5ê°œ ì €ì¥ì†Œë§Œ
                    try:
                        lang_response = requests.get(f'https://api.github.com/repos/{username}/{repo["name"]}/languages', headers=headers, timeout=5)
                        if lang_response.status_code == 200:
                            repo_langs = lang_response.json()
                            for lang, bytes_count in repo_langs.items():
                                languages[lang] = languages.get(lang, 0) + bytes_count
                    except:
                        continue

                # ìƒìœ„ ì–¸ì–´ 5ê°œ ì„ íƒ
                top_languages = sorted(languages.items(), key=lambda x: x[1], reverse=True)[:5]

                return {
                    "success": True,
                    "data": {
                        "username": username,
                        "github_url": github_url,
                        "user_info": {
                            "name": user_data.get('name', username),
                            "bio": user_data.get('bio', ''),
                            "public_repos": user_data.get('public_repos', 0),
                            "followers": user_data.get('followers', 0),
                            "following": user_data.get('following', 0),
                            "created_at": user_data.get('created_at', ''),
                            "updated_at": user_data.get('updated_at', '')
                        },
                        "repositories": [
                            {
                                "name": repo.get('name', ''),
                                "description": repo.get('description', ''),
                                "language": repo.get('language', ''),
                                "stars": repo.get('stargazers_count', 0),
                                "forks": repo.get('forks_count', 0),
                                "updated_at": repo.get('updated_at', '')
                            } for repo in repos_data[:10]
                        ],
                        "languages": [{"name": lang, "percentage": round((count / sum(languages.values())) * 100, 1)} for lang, count in top_languages],
                        "summary": {
                            "total_repos": user_data.get('public_repos', 0),
                            "total_stars": sum(repo.get('stargazers_count', 0) for repo in repos_data),
                            "top_language": top_languages[0][0] if top_languages else "N/A",
                            "most_starred_repo": max(repos_data, key=lambda x: x.get('stargazers_count', 0)).get('name', 'N/A') if repos_data else "N/A"
                        }
                    }
                }
            else:
                return {
                    "success": False,
                    "message": f"GitHub ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_response.status_code}",
                    "data": {
                        "username": username,
                        "github_url": github_url,
                        "error": f"GitHub API ì˜¤ë¥˜: {user_response.status_code}"
                    }
                }

        except Exception as e:
            return {
                "success": False,
                "message": f"GitHub ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "data": {
                    "username": username,
                    "github_url": github_url,
                    "error": str(e)
                }
            }

    except Exception as e:
        return {"success": False, "message": f"GitHub ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"}

# ì§€ì›ìë³„ ìê¸°ì†Œê°œì„œ ì¡°íšŒ API
@app.get("/api/applicants/{applicant_id}/cover-letter")
async def get_applicant_cover_letter(applicant_id: str):
    """ì§€ì›ìì˜ ìê¸°ì†Œê°œì„œ ì •ë³´ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜´"""
    try:
        # 1. ì§€ì›ì ì •ë³´ ì¡°íšŒ
        applicant = await db.applicants.find_one({"_id": ObjectId(applicant_id)})
        if not applicant:
            raise HTTPException(status_code=404, detail="ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. ìê¸°ì†Œê°œì„œ ì •ë³´ ì¡°íšŒ (applicants ì»¬ë ‰ì…˜ì—ì„œ)
        cover_letter_data = {
            "name": applicant.get("name", ""),
            "position": applicant.get("position", ""),
            "cover_letter_text": applicant.get("cover_letter_text", ""),
            "cover_letter_summary": applicant.get("cover_letter_summary", ""),
            "cover_letter_analysis": applicant.get("cover_letter_analysis", {}),
            "extracted_text": applicant.get("cover_letter_extracted_text", ""),
            "file_metadata": applicant.get("cover_letter_file_metadata", {}),
            "created_at": applicant.get("created_at"),
            "source": "applicants_collection",
            "applicant_info": {
                "id": applicant.get("_id"),  # str() ë¶ˆí•„ìš”, respond()ê°€ ì²˜ë¦¬
                "name": applicant.get("name", ""),
                "email": applicant.get("email", ""),
                "phone": applicant.get("phone", ""),
                "status": applicant.get("status", ""),
                "applied_at": applicant.get("applied_at"),
                "created_at": applicant.get("created_at")
            }
        }

        payload = {
            "success": True,
            "message": "ìê¸°ì†Œê°œì„œ ì •ë³´ ì¡°íšŒ ì„±ê³µ",
            "data": cover_letter_data
        }

        # 3. ObjectIdì™€ datetimeì„ ì•ˆì „í•˜ê²Œ ì§ë ¬í™”í•˜ëŠ” í•¨ìˆ˜
        def safe_serialize(obj):
            """ObjectIdì™€ datetimeì„ ì•ˆì „í•˜ê²Œ ì§ë ¬í™”"""
            if obj is None:
                return None
            if isinstance(obj, ObjectId):
                return str(obj)
            if isinstance(obj, datetime):
                return obj.isoformat()
            if isinstance(obj, dict):
                return {k: safe_serialize(v) for k, v in obj.items()}
            if isinstance(obj, list):
                return [safe_serialize(v) for v in obj]
            return obj

        return {
            "success": True,
            "message": "ìê¸°ì†Œê°œì„œ ì •ë³´ ì¡°íšŒ ì„±ê³µ",
            "data": safe_serialize(cover_letter_data)
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ìê¸°ì†Œê°œì„œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ìê¸°ì†Œê°œì„œ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ì§€ì›ìë³„ í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ API
@app.get("/api/applicants/{applicant_id}/portfolio")
async def get_applicant_portfolio(applicant_id: str):
    """ì§€ì›ìì˜ í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜´"""
    try:
        # 1. ì§€ì›ì ì •ë³´ ì¡°íšŒ
        applicant = await db.applicants.find_one({"_id": ObjectId(applicant_id)})
        if not applicant:
            raise HTTPException(status_code=404, detail="ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ ì¡°íšŒ (applicants ì»¬ë ‰ì…˜ì—ì„œ)
        portfolio_data = {
            "name": applicant.get("name", ""),
            "position": applicant.get("position", ""),
            "github_url": applicant.get("github_url", ""),
            "github_analysis": applicant.get("github_analysis", {}),
            "portfolio_files": applicant.get("portfolio_files", []),
            "portfolio_summary": applicant.get("portfolio_summary", ""),
            "created_at": applicant.get("created_at"),
            "source": "applicants_collection"
        }

        # 3. ì§€ì›ì ê¸°ë³¸ ì •ë³´ë„ í¬í•¨
        portfolio_data["applicant_info"] = {
            "id": str(applicant["_id"]),
            "name": applicant.get("name", ""),
            "email": applicant.get("email", ""),
            "phone": applicant.get("phone", ""),
            "status": applicant.get("status", ""),
            "applied_at": applicant.get("applied_at"),
            "created_at": applicant.get("created_at")
        }

        return {
            "success": True,
            "message": "í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ ì¡°íšŒ ì„±ê³µ",
            "data": portfolio_data
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í¬íŠ¸í´ë¦¬ì˜¤ ì¡°íšŒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ë©´ì ‘ ê´€ë ¨ API
@app.get("/api/interviews", response_model=List[Interview])
async def get_interviews():
    interviews = await db.interviews.find().to_list(1000)
    # MongoDBì˜ _idë¥¼ idë¡œ ë³€í™˜
    for interview in interviews:
        interview["id"] = str(interview["_id"])
        del interview["_id"]
    return [Interview(**interview) for interview in interviews]

@app.post("/api/interviews", response_model=Interview)
async def create_interview(interview: Interview):
    interview_dict = interview.dict()
    interview_dict["created_at"] = datetime.now()
    result = await db.interviews.insert_one(interview_dict)
    interview_dict["id"] = str(result.inserted_id)
    return Interview(**interview_dict)

# ì§€ì›ì ê´€ë ¨ API - ì¤‘ë³µ ë¼ìš°í„° ì‚­ì œ (routers/applicants.pyì—ì„œ ì²˜ë¦¬)

# ê°œë³„ ì§€ì›ì ì¡°íšŒ API - ì¤‘ë³µ ë¼ìš°í„° ì‚­ì œ (routers/applicants.pyì—ì„œ ì²˜ë¦¬)
# ì§€ì›ì í†µê³„ API - ì¤‘ë³µ ë¼ìš°í„° ì‚­ì œ (routers/applicants.pyì—ì„œ ì²˜ë¦¬)

# Vector Service API
@app.post("/api/vector/create")
async def create_vector(data: Dict[str, Any]):
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥"""
    try:
        text = data.get("text", "")
        document_id = data.get("document_id")
        metadata = data.get("metadata", {})

        # ì—¬ê¸°ì„œ ì‹¤ì œ ë²¡í„°í™” ë¡œì§ êµ¬í˜„
        # ì˜ˆ: embedding_modelì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜

        # ì„ì‹œë¡œ ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return {
            "message": "Vector created successfully",
            "document_id": document_id,
            "vector_dimension": 384,  # ì˜ˆì‹œ ì°¨ì›
            "status": "success"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë²¡í„° ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/api/vector/search")
async def search_vectors(data: Dict[str, Any]):
    """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
    try:
        query_text = data.get("query", "")
        top_k = data.get("top_k", 5)
        threshold = data.get("threshold", 0.7)

        # ì—¬ê¸°ì„œ ì‹¤ì œ ë²¡í„° ê²€ìƒ‰ ë¡œì§ êµ¬í˜„

        # ì„ì‹œë¡œ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
        return {
            "results": [
                {
                    "document_id": "doc_001",
                    "score": 0.95,
                    "text": "ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ 1",
                    "metadata": {"type": "resume", "applicant_id": "app_001"}
                },
                {
                    "document_id": "doc_002",
                    "score": 0.87,
                    "text": "ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ 2",
                    "metadata": {"type": "cover_letter", "applicant_id": "app_002"}
                }
            ],
            "total_found": 2
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

# Chunking Service API
@app.post("/api/chunking/split")
async def split_text(data: Dict[str, Any]):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ê³  DBì— ì €ì¥"""
    try:
        text = data.get("text", "")
        resume_id = data.get("resume_id")
        field_name = data.get("field_name", "")  # growthBackground, motivation, careerHistory
        chunk_size = data.get("chunk_size", 1000)
        chunk_overlap = data.get("chunk_overlap", 200)
        split_type = data.get("split_type", "recursive")

        if not resume_id:
            raise HTTPException(status_code=400, detail="resume_idê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # í…ìŠ¤íŠ¸ ë¶„í•  ë¡œì§
        chunks = []
        text_length = len(text)
        start = 0
        chunk_index = 0

        while start < text_length:
            end = min(start + chunk_size, text_length)
            chunk_text = text[start:end]

            if chunk_text.strip():  # ë¹ˆ ì²­í¬ëŠ” ì œì™¸
                chunk_id = f"chunk_{chunk_index:03d}"
                vector_id = f"resume_{resume_id}_{chunk_id}"

                chunk_doc = {
                    "resume_id": resume_id,
                    "chunk_id": chunk_id,
                    "text": chunk_text,
                    "start_pos": start,
                    "end_pos": end,
                    "chunk_index": chunk_index,
                    "field_name": field_name,
                    "vector_id": vector_id,
                    "metadata": {
                        "length": len(chunk_text),
                        "split_type": split_type,
                        "chunk_size": chunk_size,
                        "chunk_overlap": chunk_overlap
                    },
                    "created_at": datetime.now()
                }

                # MongoDBì— ì²­í¬ ì €ì¥
                result = await db.resume_chunks.insert_one(chunk_doc)
                chunk_doc["id"] = str(result.inserted_id)

                chunks.append(chunk_doc)
                chunk_index += 1

            start = end - chunk_overlap if chunk_overlap > 0 else end

            if start >= text_length:
                break

        return {
            "chunks": chunks,
            "total_chunks": len(chunks),
            "original_length": text_length,
            "resume_id": resume_id,
            "field_name": field_name,
            "split_config": {
                "chunk_size": chunk_size,
                "chunk_overlap": chunk_overlap,
                "split_type": split_type
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ ë¶„í•  ì‹¤íŒ¨: {str(e)}")

@app.get("/api/chunking/resume/{resume_id}")
async def get_resume_chunks(resume_id: str):
    """íŠ¹ì • ì´ë ¥ì„œì˜ ëª¨ë“  ì²­í¬ ì¡°íšŒ"""
    try:
        chunks = await db.resume_chunks.find({"resume_id": resume_id}).to_list(1000)

        # MongoDBì˜ _idë¥¼ idë¡œ ë³€í™˜
        for chunk in chunks:
            chunk["id"] = str(chunk["_id"])
            del chunk["_id"]

        return {
            "resume_id": resume_id,
            "chunks": [ResumeChunk(**chunk) for chunk in chunks],
            "total_chunks": len(chunks)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²­í¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/chunking/process-resume")
async def process_resume_with_chunking(data: Dict[str, Any]):
    """ì´ë ¥ì„œ ì „ì²´ë¥¼ í•„ë“œë³„ë¡œ ì²­í‚¹ ì²˜ë¦¬"""
    try:
        resume_id = data.get("resume_id")
        if not resume_id:
            raise HTTPException(status_code=400, detail="resume_idê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        # ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ
        resume = await db.resumes.find_one({"_id": ObjectId(resume_id)})
        if not resume:
            raise HTTPException(status_code=404, detail="ì´ë ¥ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        chunk_size = data.get("chunk_size", 800)
        chunk_overlap = data.get("chunk_overlap", 150)

        # ì²­í‚¹í•  í•„ë“œë“¤
        fields_to_chunk = ["growthBackground", "motivation", "careerHistory"]
        all_chunks = []

        for field_name in fields_to_chunk:
            field_text = resume.get(field_name, "")
            if field_text and field_text.strip():
                # í•„ë“œë³„ ì²­í‚¹ ì²˜ë¦¬
                field_chunks = []
                text_length = len(field_text)
                start = 0
                chunk_index = 0

                while start < text_length:
                    end = min(start + chunk_size, text_length)
                    chunk_text = field_text[start:end]

                    if chunk_text.strip():
                        chunk_id = f"{field_name}_chunk_{chunk_index:03d}"
                        vector_id = f"resume_{resume_id}_{chunk_id}"

                        chunk_doc = {
                            "resume_id": resume_id,
                            "chunk_id": chunk_id,
                            "text": chunk_text,
                            "start_pos": start,
                            "end_pos": end,
                            "chunk_index": chunk_index,
                            "field_name": field_name,
                            "vector_id": vector_id,
                            "metadata": {
                                "applicant_name": resume.get("name", ""),
                                "position": resume.get("position", ""),
                                "department": resume.get("department", ""),
                                "length": len(field_text)
                            },
                            "created_at": datetime.now()
                        }

                        result = await db.resume_chunks.insert_one(chunk_doc)
                        chunk_doc["id"] = str(result.inserted_id)
                        field_chunks.append(chunk_doc)
                        chunk_index += 1

                    start = end - chunk_overlap if chunk_overlap > 0 else end
                    if start >= text_length:
                        break

                all_chunks.extend(field_chunks)

        return {
            "resume_id": resume_id,
            "applicant_name": resume.get("name", ""),
            "processed_fields": fields_to_chunk,
            "total_chunks": len(all_chunks),
            "chunks_by_field": {
                field: len([c for c in all_chunks if c["field_name"] == field])
                for field in fields_to_chunk
            },
            "chunks": all_chunks
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë ¥ì„œ ì²­í‚¹ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/chunking/merge")
async def merge_chunks(data: Dict[str, Any]):
    """ì²­í¬ë“¤ì„ ë³‘í•©"""
    try:
        chunks = data.get("chunks", [])
        separator = data.get("separator", "\n\n")

        # ì²­í¬ ë³‘í•©
        merged_text = separator.join([chunk.get("text", "") for chunk in chunks])

        return {
            "merged_text": merged_text,
            "total_length": len(merged_text),
            "chunks_merged": len(chunks),
            "separator_used": separator
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²­í¬ ë³‘í•© ì‹¤íŒ¨: {str(e)}")

# Similarity Service API
@app.post("/api/similarity/compare")
async def compare_similarity(data: Dict[str, Any]):
    """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        text1 = data.get("text1", "")
        text2 = data.get("text2", "")
        method = data.get("method", "cosine")  # cosine, jaccard, levenshtein

        # ì—¬ê¸°ì„œ ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚° ë¡œì§ êµ¬í˜„
        # ì˜ˆ: sentence-transformersì˜ cosine similarity

        # ì„ì‹œë¡œ ìœ ì‚¬ë„ ì ìˆ˜ ë°˜í™˜
        import random
        similarity_score = random.uniform(0.3, 0.95)  # ì„ì‹œ ì ìˆ˜

        return {
            "similarity_score": round(similarity_score, 4),
            "method": method,
            "text1_length": len(text1),
            "text2_length": len(text2),
            "comparison_result": {
                "highly_similar": similarity_score > 0.8,
                "moderately_similar": 0.5 < similarity_score <= 0.8,
                "low_similar": similarity_score <= 0.5
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")

@app.post("/api/similarity/batch")
async def batch_similarity(data: Dict[str, Any]):
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë“¤ ê°„ì˜ ì¼ê´„ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        texts = data.get("texts", [])
        reference_text = data.get("reference_text", "")
        method = data.get("method", "cosine")
        threshold = data.get("threshold", 0.7)

        # ë°°ì¹˜ ìœ ì‚¬ë„ ê³„ì‚°
        results = []
        import random

        for i, text in enumerate(texts):
            similarity_score = random.uniform(0.2, 0.95)  # ì„ì‹œ ì ìˆ˜
            results.append({
                "index": i,
                "text_preview": text[:100] + "..." if len(text) > 100 else text,
                "similarity_score": round(similarity_score, 4),
                "above_threshold": similarity_score >= threshold
            })

        # ì„ê³„ê°’ ì´ìƒì¸ ê²°ê³¼ë“¤ í•„í„°ë§
        filtered_results = [r for r in results if r["above_threshold"]]

        return {
            "results": results,
            "filtered_results": filtered_results,
            "total_compared": len(texts),
            "above_threshold_count": len(filtered_results),
            "method": method,
            "threshold": threshold,
            "reference_text_length": len(reference_text)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")

@app.get("/api/similarity/metrics")
async def get_similarity_metrics():
    """ìœ ì‚¬ë„ ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        # ì„ì‹œ ë©”íŠ¸ë¦­ ë°ì´í„°
        return {
            "total_comparisons": 1250,
            "average_similarity": 0.67,
            "supported_methods": ["cosine", "jaccard", "levenshtein", "semantic"],
            "performance_stats": {
                "average_processing_time_ms": 45,
                "comparisons_per_second": 220,
                "cache_hit_rate": 0.78
            },
            "usage_by_method": {
                "cosine": 850,
                "semantic": 300,
                "jaccard": 70,
                "levenshtein": 30
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ API ğŸ†•
@app.post("/api/resume/search/multi-hybrid")
async def search_resumes_multi_hybrid(data: Dict[str, Any]):
    """ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë²¡í„° + í…ìŠ¤íŠ¸ + í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ê²°í•©"""
    try:
        query = data.get("query", "")
        search_type = data.get("type", "resume")
        limit = data.get("limit", 10)

        print(f"[API] ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìš”ì²­ - ì¿¼ë¦¬: '{query}', ì œí•œ: {limit}")

        if not query or not query.strip():
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # SimilarityServiceì˜ ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        result = await similarity_service.search_resumes_multi_hybrid(
            query=query,
            collection=db.applicants,
            search_type=search_type,
            limit=limit
        )

        if not result["success"]:
            raise HTTPException(status_code=500, detail="ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        return {
            "success": True,
            "message": f"ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: '{query}'",
            "data": result["data"]
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[API] ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë‹¤ì¤‘ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

# í‚¤ì›Œë“œ ê²€ìƒ‰ API
@app.post("/api/resume/search/keyword")
async def search_resumes_keyword(data: Dict[str, Any]):
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì´ë ¥ì„œ ê²€ìƒ‰ (BM25)"""
    try:
        query = data.get("query", "")
        limit = data.get("limit", 10)

        print(f"[API] í‚¤ì›Œë“œ ê²€ìƒ‰ ìš”ì²­ - ì¿¼ë¦¬: '{query}', ì œí•œ: {limit}")

        if not query or not query.strip():
            raise HTTPException(status_code=400, detail="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # KeywordSearchServiceë¥¼ í†µí•œ BM25 ê²€ìƒ‰
        result = await similarity_service.keyword_search_service.search_by_keywords(
            query=query,
            collection=db.applicants,
            limit=limit
        )

        if not result["success"]:
            raise HTTPException(status_code=500, detail=result.get("message", "í‚¤ì›Œë“œ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."))

        return {
            "success": True,
            "message": result["message"],
            "data": {
                "query": result["query"],
                "results": result["results"],
                "total": result["total"],
                "search_method": "keyword_bm25",
                "query_tokens": result.get("query_tokens", [])
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[API] í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

# í‚¤ì›Œë“œ ê²€ìƒ‰ ì¸ë±ìŠ¤ ê´€ë¦¬ API
@app.post("/api/resume/search/keyword/rebuild-index")
async def rebuild_keyword_index():
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
    try:
        print(f"[API] í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ìš”ì²­")

        # KeywordSearchServiceë¥¼ í†µí•œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
        result = await similarity_service.keyword_search_service.build_index(db.applicants)

        if not result["success"]:
            raise HTTPException(status_code=500, detail=result.get("message", "ì¸ë±ìŠ¤ ì¬êµ¬ì¶•ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."))

        return {
            "success": True,
            "message": result["message"],
            "data": {
                "total_documents": result["total_documents"],
                "index_created_at": result["index_created_at"]
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[API] í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨: {str(e)}")

@app.get("/api/resume/search/keyword/stats")
async def get_keyword_search_stats():
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ"""
    try:
        stats = await similarity_service.keyword_search_service.get_index_stats()

        return {
            "success": True,
            "data": stats
        }

    except Exception as e:
        print(f"[API] í‚¤ì›Œë“œ ê²€ìƒ‰ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‚¤ì›Œë“œ ê²€ìƒ‰ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# ì´ë ¥ì„œ ìœ ì‚¬ë„ ì²´í¬ API
@app.post("/api/resume/similarity-check/{resume_id}")
async def check_resume_similarity(resume_id: str):
    """íŠ¹ì • ì´ë ¥ì„œì˜ ìœ ì‚¬ë„ ì²´í¬ (ë‹¤ë¥¸ ëª¨ë“  ì´ë ¥ì„œì™€ ë¹„êµ)"""
    try:
        print(f"[INFO] ìœ ì‚¬ë„ ì²´í¬ ìš”ì²­ - resume_id: {resume_id}")

        # SimilarityServiceë¥¼ í†µí•œ ì²­í‚¹ ê¸°ë°˜ ìœ ì‚¬ë„ ë¶„ì„
        result = await similarity_service.find_similar_documents_by_chunks(resume_id, db.applicants, "resume", 50)

        # í˜„ì¬ ì´ë ¥ì„œ ì •ë³´ ì¡°íšŒ
        current_resume = await db.applicants.find_one({"_id": ObjectId(resume_id)})
        print(f"[INFO] ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼: {current_resume is not None}")

        # ì²­í‚¹ ê¸°ë°˜ API ì‘ë‹µ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        similarity_results = []
        for similar in result["data"]["similar_resumes"]:
            # ì²­í‚¹ ìƒì„¸ ì •ë³´ì—ì„œ í•„ë“œë³„ ìœ ì‚¬ë„ ì¶”ì¶œ
            chunk_details = similar.get("chunk_details", {})
            field_similarities = {
                "growthBackground": 0.0,
                "motivation": 0.0,
                "careerHistory": 0.0
            }

            # ì²­í¬ ë§¤ì¹­ì—ì„œ í•„ë“œë³„ ìµœê³  ì ìˆ˜ ì¶”ì¶œ
            for chunk_key, chunk_info in chunk_details.items():
                if "growth_background" in chunk_key:
                    field_similarities["growthBackground"] = max(field_similarities["growthBackground"], chunk_info["score"])
                elif "motivation" in chunk_key:
                    field_similarities["motivation"] = max(field_similarities["motivation"], chunk_info["score"])
                elif "career_history" in chunk_key:
                    field_similarities["careerHistory"] = max(field_similarities["careerHistory"], chunk_info["score"])

            similarity_result = {
                "resume_id": str(similar["resume"]["_id"]),
                "applicant_name": similar["resume"].get("name", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "position": similar["resume"].get("position", ""),
                "department": similar["resume"].get("department", ""),
                "overall_similarity": round(similar["similarity_score"], 4),
                "field_similarities": {
                    "growthBackground": round(field_similarities["growthBackground"], 4),
                    "motivation": round(field_similarities["motivation"], 4),
                    "careerHistory": round(field_similarities["careerHistory"], 4)
                },
                "chunk_matches": similar.get("chunk_matches", 0),
                "chunk_details": chunk_details,
                "is_high_similarity": similar["similarity_score"] > 0.7,
                "is_moderate_similarity": 0.4 <= similar["similarity_score"] <= 0.7,
                "is_low_similarity": similar["similarity_score"] < 0.4,
                "llm_analysis": similar.get("llm_analysis")
            }
            similarity_results.append(similarity_result)

        # ë‹¤ë¥¸ ëª¨ë“  ì´ë ¥ì„œ ì¡°íšŒ (í˜„ì¬ ì´ë ¥ì„œ ì œì™¸)
        other_resumes = await db.applicants.find({"_id": {"$ne": ObjectId(resume_id)}}).to_list(1000)

        # í˜„ì¬ ì´ë ¥ì„œì˜ ë¹„êµ í…ìŠ¤íŠ¸ (ìœ ì‚¬ë„ ê³„ì‚° í•„ë“œ)
        current_fields = {
            "growthBackground": current_resume.get("growthBackground", ""),
            "motivation": current_resume.get("motivation", ""),
            "careerHistory": current_resume.get("careerHistory", "")
        }

        # ì „ì²´ í…ìŠ¤íŠ¸ ì¡°í•©
        current_text = " ".join([text for text in current_fields.values() if text])

        similarity_results = []

        for other_resume in other_resumes:
            other_id = str(other_resume["_id"])

            # ë‹¤ë¥¸ ì´ë ¥ì„œì˜ ë¹„êµ í…ìŠ¤íŠ¸
            other_fields = {
                "growthBackground": other_resume.get("growthBackground", ""),
                "motivation": other_resume.get("motivation", ""),
                "careerHistory": other_resume.get("careerHistory", "")
            }
            other_text = " ".join([text for text in other_fields.values() if text])

            # ì‹¤ì œ ìœ ì‚¬ë„ ê³„ì‚° ì‚¬ìš©
            try:
                print(f"ğŸ’« ì´ë ¥ì„œ ê°„ ìœ ì‚¬ë„ ê³„ì‚° ì‹œì‘: {resume_id} vs {other_id}")

                # SimilarityServiceì˜ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° ë©”ì„œë“œ ì§ì ‘ í˜¸ì¶œ
                text_similarity = similarity_service._calculate_text_similarity(current_resume, other_resume)
                overall_similarity = text_similarity if text_similarity is not None else 0.0

                print(f"ğŸ“Š í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²°ê³¼: {overall_similarity:.3f}")

                # í•„ë“œë³„ ìœ ì‚¬ë„ ê³„ì‚°
                field_similarities = {}
                for field_name in current_fields.keys():
                    if current_fields[field_name] and other_fields[field_name]:
                        # í•„ë“œë³„ ê°œë³„ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
                        field_sim = similarity_service._calculate_text_similarity(
                            {field_name: current_fields[field_name]},
                            {field_name: other_fields[field_name]}
                        )
                        field_similarities[field_name] = field_sim if field_sim is not None else 0.0
                        print(f"ğŸ“‹ {field_name} ìœ ì‚¬ë„: {field_similarities[field_name]:.3f}")
                    else:
                        field_similarities[field_name] = 0.0

            except Exception as e:
                print(f"[ERROR] ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()

                # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                import random
                overall_similarity = random.uniform(0.1, 0.9)
                field_similarities = {}
                for field_name in current_fields.keys():
                    if current_fields[field_name] and other_fields[field_name]:
                        field_similarities[field_name] = random.uniform(0.0, 1.0)
                    else:
                        field_similarities[field_name] = 0.0

            # LLM ë¶„ì„ ì¶”ê°€ (ìœ ì‚¬ë„ê°€ ì¼ì • ìˆ˜ì¤€ ì´ìƒì¼ ë•Œë§Œ)
            llm_analysis = None

            if overall_similarity >= 0.3:  # 30% ì´ìƒ ìœ ì‚¬í•  ë•Œë§Œ LLM ë¶„ì„
                try:
                    print(f"[API] LLM ë¶„ì„ ì‹œì‘ - ìœ ì‚¬ë„: {overall_similarity:.3f}")
                    llm_analysis = await similarity_service.llm_service.analyze_plagiarism_suspicion(
                        similarity_score=overall_similarity,
                        similar_documents=[{
                            "similarity_score": overall_similarity,
                            "name": other_resume.get("name", "Unknown"),
                            "basic_info_names": other_resume.get("name", "Unknown")
                        }],
                        document_type="resume"
                    )
                    print(f"[API] LLM ë¶„ì„ ì™„ë£Œ")
                except Exception as llm_error:
                    print(f"[API] LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {llm_error}")
                    llm_analysis = {
                        "success": False,
                        "error": str(llm_error),
                        "analysis": "LLM ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                    }

            similarity_result = {
                "resume_id": other_id,
                "applicant_name": other_resume.get("name", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "position": other_resume.get("position", ""),
                "department": other_resume.get("department", ""),
                "overall_similarity": round(overall_similarity, 4),
                "field_similarities": {
                    "growthBackground": round(field_similarities["growthBackground"], 4),
                    "motivation": round(field_similarities["motivation"], 4),
                    "careerHistory": round(field_similarities["careerHistory"], 4)
                },
                "is_high_similarity": overall_similarity > 0.7,
                "is_moderate_similarity": 0.4 <= overall_similarity <= 0.7,
                "is_low_similarity": overall_similarity < 0.4,
                "llm_analysis": llm_analysis
            }

            similarity_results.append(similarity_result)

        # ìœ ì‚¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        similarity_results.sort(key=lambda x: x["overall_similarity"], reverse=True)

        # ì „ì²´ í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ì¶”ê°€
        plagiarism_analysis = None
        high_similarity_results = [r for r in similarity_results if r["overall_similarity"] >= 0.3]

        if high_similarity_results:
            try:
                print(f"[API] í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ì‹œì‘")
                plagiarism_analysis = await similarity_service.llm_service.analyze_plagiarism_suspicion(
                    original_resume=current_resume,
                    similar_resumes=high_similarity_results
                )
                print(f"[API] í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ì™„ë£Œ")
            except Exception as plag_error:
                print(f"[API] í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {plag_error}")
                plagiarism_analysis = {
                    "success": False,
                    "error": str(plag_error),
                    "suspicion_level": "UNKNOWN",
                    "suspicion_score": 0.0,
                    "suspicion_score_percent": 0,
                    "analysis": "í‘œì ˆ ì˜ì‹¬ë„ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }

        # í†µê³„ ì •ë³´
        high_similarity_count = len([r for r in similarity_results if r["is_high_similarity"]])
        moderate_similarity_count = len([r for r in similarity_results if r["is_moderate_similarity"]])
        low_similarity_count = len([r for r in similarity_results if r["is_low_similarity"]])

        return {
            "current_resume": {
                "id": resume_id,
                "name": current_resume.get("name", ""),
                "position": current_resume.get("position", ""),
                "department": current_resume.get("department", "")
            },
            "similarity_results": similarity_results,
            "statistics": {
                "total_compared": len(similarity_results),
                "high_similarity_count": high_similarity_count,
                "moderate_similarity_count": moderate_similarity_count,
                "low_similarity_count": low_similarity_count,
                "average_similarity": round(sum([r["overall_similarity"] for r in similarity_results]) / len(similarity_results) if similarity_results else 0, 4)
            },
            "top_similar": similarity_results[:5] if similarity_results else [],
            "plagiarism_analysis": plagiarism_analysis,
            "analysis_timestamp": datetime.now().isoformat()
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìœ ì‚¬ë„ ì²´í¬ ì‹¤íŒ¨: {str(e)}")

# ì»¤ë²„ë ˆí„° ìœ ì‚¬ë„ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/coverletter/similarity-check/{applicant_id}")
async def check_coverletter_similarity(
    applicant_id: str,
    mongo_service: MongoService = Depends(get_mongo_service)
):
    """ìê¸°ì†Œê°œì„œ í‘œì ˆì²´í¬ (í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ëª… ì—”ë“œí¬ì¸íŠ¸)"""
    try:
        print(f"[INFO] ìì†Œì„œ í‘œì ˆì²´í¬ ìš”ì²­ - applicant_id: {applicant_id}")

        # 1. ì§€ì›ì ì¡´ì¬ í™•ì¸
        applicant = await mongo_service.get_applicant_by_id(applicant_id)
        if not applicant:
            print(f"[ERROR] ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - applicant_id: {applicant_id}")
            raise HTTPException(status_code=404, detail="ì§€ì›ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        print(f"[INFO] ì§€ì›ì ì •ë³´ í™•ì¸ - applicant: {applicant}")
        print(f"[INFO] ì§€ì›ì í•„ë“œë“¤: {list(applicant.keys())}")

        # 2. ìì†Œì„œ ì¡´ì¬ í™•ì¸
        cover_letter_id = applicant.get("cover_letter_id")
        print(f"[INFO] ìì†Œì„œ ID í™•ì¸ - cover_letter_id: {cover_letter_id}")

        if not cover_letter_id:
            print(f"[ERROR] ìì†Œì„œ IDê°€ ì—†ìŒ - applicant_id: {applicant_id}")
            raise HTTPException(status_code=404, detail="ìì†Œì„œê°€ ì—†ìŠµë‹ˆë‹¤")

        # 3. ìì†Œì„œ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        from bson import ObjectId
        from motor.motor_asyncio import AsyncIOMotorClient

        mongo_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017/hireme")
        client = AsyncIOMotorClient(mongo_uri)
        db = client.hireme

        try:
            # ObjectId ë³€í™˜ ì‹œë„
            try:
                object_id = ObjectId(cover_letter_id)
            except Exception as e:
                print(f"[ERROR] ì˜ëª»ëœ ObjectId í˜•ì‹: {cover_letter_id}")
                raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ìì†Œì„œ ID í˜•ì‹ì…ë‹ˆë‹¤")

            cover_letter = await db.cover_letters.find_one({"_id": object_id})

            if not cover_letter:
                raise HTTPException(status_code=404, detail="ìì†Œì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # ìì†Œì„œ ë‚´ìš© ì¶”ì¶œ (content ë˜ëŠ” extracted_text í•„ë“œì—ì„œ)
            cover_letter_text = cover_letter.get("content", "") or cover_letter.get("extracted_text", "")

            # ìì†Œì„œ ë°ì´í„°ì— extracted_text í•„ë“œê°€ ì—†ìœ¼ë©´ contentë¥¼ ì‚¬ìš©
            if not cover_letter.get("extracted_text"):
                cover_letter["extracted_text"] = cover_letter_text

            if not cover_letter_text:
                print(f"[WARNING] ìì†Œì„œ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ - applicant_id: {applicant_id}")
                return {
                    "status": "success",
                    "applicant_id": applicant_id,
                    "plagiarism_result": {
                        "status": "no_content",
                        "message": "ìì†Œì„œ ë‚´ìš©ì´ ì—†ì–´ í‘œì ˆ ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "similar_count": 0,
                        "suspicion_level": "UNKNOWN"
                    },
                    "message": "ìì†Œì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
                }

            print(f"[INFO] ìì†Œì„œ ë‚´ìš© ë°œê²¬ - ê¸¸ì´: {len(cover_letter_text)}ì")
            print(f"[INFO] ìì†Œì„œ í•„ë“œë“¤: {list(cover_letter.keys())}")

            # 4. ìœ ì‚¬ë„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
            similarity_service = get_similarity_service()

            # 5. ìì†Œì„œ í‘œì ˆì²´í¬ ìˆ˜í–‰ (ì²­í‚¹ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‚¬ìš©)
            # ìì†Œì„œ ë°ì´í„°ë¥¼ ì§ì ‘ ì „ë‹¬í•˜ì—¬ ì²­í‚¹ ì²˜ë¦¬
            result = await similarity_service.find_similar_documents_by_chunks(
                document_id=cover_letter_id,
                collection=db.cover_letters,
                document_type="cover_letter",
                limit=10
            )

        except HTTPException:
            raise
        except Exception as e:
            print(f"[ERROR] ìì†Œì„œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(status_code=500, detail="ìì†Œì„œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
        finally:
            client.close()

        # ê²°ê³¼ ê²€ì¦ ë° í´ë°± ì²˜ë¦¬
        if not result or not result.get("success"):
            print(f"[WARNING] ìì†Œì„œ í‘œì ˆì²´í¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ - í´ë°± ì‘ë‹µ ìƒì„±")
            return {
                "status": "success",
                "applicant_id": applicant_id,
                "plagiarism_result": {
                    "status": "no_similar_documents",
                    "message": "ìœ ì‚¬í•œ ìì†Œì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ í‘œì ˆ ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "similar_count": 0,
                    "suspicion_level": "UNKNOWN",
                    "debug_info": {
                        "cover_letter_id": cover_letter_id,
                        "content_length": len(cover_letter_text),
                        "has_extracted_text": bool(cover_letter.get("extracted_text")),
                        "cover_letter_fields": list(cover_letter.keys())
                    }
                },
                "message": "ìì†Œì„œ í‘œì ˆì²´í¬ ì™„ë£Œ (ìœ ì‚¬ ë¬¸ì„œ ì—†ìŒ)"
            }

        return {
            "status": "success",
            "applicant_id": applicant_id,
            "plagiarism_result": result,
            "message": "ìì†Œì„œ í‘œì ˆì²´í¬ ì™„ë£Œ"
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ìì†Œì„œ í‘œì ˆì²´í¬ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ìì†Œì„œ í‘œì ˆì²´í¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )



# ë©”ì¼ í…œí”Œë¦¿ ë° ì„¤ì • ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/mail-templates")
async def get_mail_templates():
    """ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ"""
    try:
        templates = await db.mail_templates.find_one({"_id": "default"})

        # ê¸°ì¡´ í…œí”Œë¦¿ì´ ìˆë”ë¼ë„ ìƒˆë¡œìš´ ìƒíƒœ íƒ€ì…ë“¤ì´ ì—†ìœ¼ë©´ ì¬ìƒì„±
        should_recreate = False
        if templates:
            required_types = ["passed", "document_passed", "final_passed", "rejected", "document_rejected"]
            for required_type in required_types:
                if required_type not in templates:
                    should_recreate = True
                    break

        if not templates or should_recreate:
            # ê¸°ì¡´ í…œí”Œë¦¿ì´ ìˆìœ¼ë©´ ì‚­ì œ
            if templates:
                await db.mail_templates.delete_one({"_id": "default"})

            # ê¸°ë³¸ í…œí”Œë¦¿ ìƒì„±
            default_templates = {
                "_id": "default",
                "passed": {
                    "subject": "ì¶•í•˜í•©ë‹ˆë‹¤! ì„œë¥˜ ì „í˜• í•©ê²© ì•ˆë‚´",
                    "content": """ì•ˆë…•í•˜ì„¸ìš”, {applicant_name}ë‹˜

ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! {job_posting_title} í¬ì§€ì…˜ì— ëŒ€í•œ ì„œë¥˜ ì „í˜•ì— í•©ê²©í•˜ì…¨ìŠµë‹ˆë‹¤.

ë‹¤ìŒ ë‹¨ê³„ì¸ ë©´ì ‘ ì¼ì •ì€ ì¶”í›„ ë³„ë„ë¡œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{company_name} ì±„ìš©íŒ€"""
                },
                "document_passed": {
                    "subject": "ì¶•í•˜í•©ë‹ˆë‹¤! ì„œë¥˜ ì „í˜• í•©ê²© ì•ˆë‚´",
                    "content": """ì•ˆë…•í•˜ì„¸ìš”, {applicant_name}ë‹˜

ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! {job_posting_title} í¬ì§€ì…˜ì— ëŒ€í•œ ì„œë¥˜ ì „í˜•ì— í•©ê²©í•˜ì…¨ìŠµë‹ˆë‹¤.

ë‹¤ìŒ ë‹¨ê³„ì¸ ë©´ì ‘ ì¼ì •ì€ ì¶”í›„ ë³„ë„ë¡œ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{company_name} ì±„ìš©íŒ€"""
                },
                "final_passed": {
                    "subject": "ì¶•í•˜í•©ë‹ˆë‹¤! ìµœì¢… í•©ê²© ì•ˆë‚´",
                    "content": """ì•ˆë…•í•˜ì„¸ìš”, {applicant_name}ë‹˜

ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! {job_posting_title} í¬ì§€ì…˜ì— ëŒ€í•œ ìµœì¢… ì „í˜•ì— í•©ê²©í•˜ì…¨ìŠµë‹ˆë‹¤.

ì…ì‚¬ ê´€ë ¨ ìƒì„¸ ì•ˆë‚´ëŠ” ì¶”í›„ ë³„ë„ë¡œ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{company_name} ì±„ìš©íŒ€"""
                },
                "rejected": {
                    "subject": "ì„œë¥˜ ì „í˜• ê²°ê³¼ ì•ˆë‚´",
                    "content": """ì•ˆë…•í•˜ì„¸ìš”, {applicant_name}ë‹˜

{job_posting_title} í¬ì§€ì…˜ì— ëŒ€í•œ ì„œë¥˜ ì „í˜• ê²°ê³¼ë¥¼ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.

ì•ˆíƒ€ê¹ê²Œë„ ì´ë²ˆ ì „í˜•ì—ì„œëŠ” í•©ê²©í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
ì•ìœ¼ë¡œ ë” ì¢‹ì€ ê¸°íšŒê°€ ìˆì„ ë•Œ ë‹¤ì‹œ ì§€ì›í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{company_name} ì±„ìš©íŒ€"""
                },
                "document_rejected": {
                    "subject": "ì„œë¥˜ ì „í˜• ê²°ê³¼ ì•ˆë‚´",
                    "content": """ì•ˆë…•í•˜ì„¸ìš”, {applicant_name}ë‹˜

{job_posting_title} í¬ì§€ì…˜ì— ëŒ€í•œ ì„œë¥˜ ì „í˜• ê²°ê³¼ë¥¼ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.

ì•ˆíƒ€ê¹ê²Œë„ ì´ë²ˆ ì „í˜•ì—ì„œëŠ” í•©ê²©í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
ì•ìœ¼ë¡œ ë” ì¢‹ì€ ê¸°íšŒê°€ ìˆì„ ë•Œ ë‹¤ì‹œ ì§€ì›í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
{company_name} ì±„ìš©íŒ€"""
                },
                "created_at": datetime.now(),
                "updated_at": datetime.now()
            }
            await db.mail_templates.insert_one(default_templates)
            templates = default_templates

        # _id ì œê±°í•˜ê³  ë°˜í™˜
        templates.pop("_id", None)
        return templates
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/mail-templates")
async def save_mail_templates(templates: Dict[str, Any]):
    """ë©”ì¼ í…œí”Œë¦¿ ì €ì¥"""
    try:
        update_data = {
            "passed": templates.get("passed", {}),
            "document_passed": templates.get("document_passed", {}),
            "final_passed": templates.get("final_passed", {}),
            "rejected": templates.get("rejected", {}),
            "document_rejected": templates.get("document_rejected", {}),
            "updated_at": datetime.now()
        }

        result = await db.mail_templates.update_one(
            {"_id": "default"},
            {"$set": update_data},
            upsert=True
        )

        return {"success": True, "message": "ë©”ì¼ í…œí”Œë¦¿ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ì¼ í…œí”Œë¦¿ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

@app.get("/api/mail-settings")
async def get_mail_settings():
    """ë©”ì¼ ì„¤ì • ì¡°íšŒ"""
    try:
        settings = await db.mail_settings.find_one({"_id": "default"})
        if not settings:
            # ê¸°ë³¸ ì„¤ì • ìƒì„±
            default_settings = {
                "_id": "default",
                "senderEmail": "",
                "senderPassword": "",
                "senderName": "",
                "smtpServer": "smtp.gmail.com",
                "smtpPort": 587,
                "created_at": datetime.now(),
                "updated_at": datetime.now()
            }
            await db.mail_settings.insert_one(default_settings)
            settings = default_settings

        # _id ì œê±°í•˜ê³  ë°˜í™˜
        settings.pop("_id", None)
        return settings
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ì¼ ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/mail-settings")
async def save_mail_settings(settings: Dict[str, Any]):
    """ë©”ì¼ ì„¤ì • ì €ì¥"""
    try:
        update_data = {
            "senderEmail": settings.get("senderEmail", ""),
            "senderPassword": settings.get("senderPassword", ""),
            "senderName": settings.get("senderName", ""),
            "smtpServer": settings.get("smtpServer", "smtp.gmail.com"),
            "smtpPort": settings.get("smtpPort", 587),
            "updated_at": datetime.now()
        }

        result = await db.mail_settings.update_one(
            {"_id": "default"},
            {"$set": update_data},
            upsert=True
        )

        return {"success": True, "message": "ë©”ì¼ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©”ì¼ ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {str(e)}")

@app.post("/api/send-test-mail")
async def send_test_mail(request: Request):
    """í…ŒìŠ¤íŠ¸ ë©”ì¼ ë°œì†¡"""
    try:
        import smtplib
        from email.mime.multipart import MIMEMultipart
        from email.mime.text import MIMEText

        data = await request.json()
        print(f"ë°›ì€ ë°ì´í„°: {data}")  # ë””ë²„ê¹…ìš© ë¡œê·¸

        test_email = data.get("testEmail")
        mail_settings = data.get("mailSettings")

        print(f"í…ŒìŠ¤íŠ¸ ì´ë©”ì¼: {test_email}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        print(f"ë©”ì¼ ì„¤ì •: {mail_settings}")  # ë””ë²„ê¹…ìš© ë¡œê·¸

        if not test_email or not mail_settings:
            print("í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ ë˜ëŠ” ë©”ì¼ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            raise HTTPException(status_code=400, detail="í…ŒìŠ¤íŠ¸ ì´ë©”ì¼ê³¼ ë©”ì¼ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ
        mail_templates = await db.mail_templates.find_one({"_id": "default"})
        if not mail_templates:
            raise HTTPException(status_code=400, detail="ë©”ì¼ í…œí”Œë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # í…ŒìŠ¤íŠ¸ ë©”ì¼ ë‚´ìš© ìƒì„±
        template = mail_templates.get("passed", {})
        subject = template.get("subject", "í…ŒìŠ¤íŠ¸ ë©”ì¼")
        content = template.get("content", "í…ŒìŠ¤íŠ¸ ë©”ì¼ì…ë‹ˆë‹¤.")

        # ë³€ìˆ˜ ì¹˜í™˜
        content = content.format(
            applicant_name="í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì",
            job_posting_title="í…ŒìŠ¤íŠ¸ ì±„ìš©ê³µê³ ",
            company_name="í…ŒìŠ¤íŠ¸ íšŒì‚¬",
            position="í…ŒìŠ¤íŠ¸ ì§ë¬´"
        )

        # ë©”ì¼ ê°ì²´ ìƒì„±
        msg = MIMEMultipart()
        msg['From'] = f"{mail_settings.get('senderName', '')} <{mail_settings.get('senderEmail')}>"
        msg['To'] = test_email
        msg['Subject'] = f"[í…ŒìŠ¤íŠ¸] {subject}"

        # ë©”ì¼ ë³¸ë¬¸ ì¶”ê°€
        msg.attach(MIMEText(content, 'plain', 'utf-8'))

        # SMTP ì„œë²„ ì—°ê²° ë° ë©”ì¼ ë°œì†¡
        try:
            print(f"SMTP ì„œë²„ ì—°ê²° ì‹œë„: {mail_settings.get('smtpServer')}:{mail_settings.get('smtpPort')}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            print(f"ë°œì†¡ì ì´ë©”ì¼: {mail_settings.get('senderEmail')}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            print(f"ë°œì†¡ì ë¹„ë°€ë²ˆí˜¸ ê¸¸ì´: {len(mail_settings.get('senderPassword', ''))}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            print(f"ë°œì†¡ì ë¹„ë°€ë²ˆí˜¸: {mail_settings.get('senderPassword', '')[:4]}***")  # ë””ë²„ê¹…ìš© ë¡œê·¸ (ì• 4ìë¦¬ë§Œ)

            smtp_port = mail_settings.get('smtpPort', 587)
            smtp_server = mail_settings.get('smtpServer', 'smtp.gmail.com')

            # í¬íŠ¸ 465ì¸ ê²½ìš° SSL ì‚¬ìš©
            if smtp_port == 465:
                with smtplib.SMTP_SSL(smtp_server, smtp_port) as server:
                    print("SMTP SSL ì„œë²„ ì—°ê²° ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    print(f"ë¡œê·¸ì¸ ì‹œë„: {mail_settings.get('senderEmail')}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.login(mail_settings.get('senderEmail'), mail_settings.get('senderPassword'))
                    print("ë¡œê·¸ì¸ ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.send_message(msg)
                    print("ë©”ì¼ ë°œì†¡ ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            else:
                with smtplib.SMTP(smtp_server, smtp_port) as server:
                    print("SMTP ì„œë²„ ì—°ê²° ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.starttls()
                    print("STARTTLS ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    print(f"ë¡œê·¸ì¸ ì‹œë„: {mail_settings.get('senderEmail')}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.login(mail_settings.get('senderEmail'), mail_settings.get('senderPassword'))
                    print("ë¡œê·¸ì¸ ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸
                    server.send_message(msg)
                    print("ë©”ì¼ ë°œì†¡ ì„±ê³µ")  # ë””ë²„ê¹…ìš© ë¡œê·¸

            return {
                "success": True,
                "message": "í…ŒìŠ¤íŠ¸ ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "subject": f"[í…ŒìŠ¤íŠ¸] {subject}",
                "to": test_email
            }

        except smtplib.SMTPAuthenticationError as e:
            print(f"ì¸ì¦ ì‹¤íŒ¨: {str(e)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            raise HTTPException(status_code=400, detail="ì¸ì¦ ì‹¤íŒ¨. ì´ë©”ì¼ ì£¼ì†Œì™€ ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        except smtplib.SMTPException as e:
            print(f"SMTP ì˜¤ë¥˜: {str(e)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            raise HTTPException(status_code=400, detail=f"SMTP ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            print(f"ë©”ì¼ ë°œì†¡ ì˜¤ë¥˜: {str(e)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
            raise HTTPException(status_code=500, detail=f"ë©”ì¼ ë°œì†¡ ì˜¤ë¥˜: {str(e)}")

    except HTTPException:
        raise
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")  # ë””ë²„ê¹…ìš© ë¡œê·¸
        raise HTTPException(status_code=500, detail=f"í…ŒìŠ¤íŠ¸ ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/api/send-bulk-mail")
async def send_bulk_mail(request: Request):
    """ëŒ€ëŸ‰ ë©”ì¼ ë°œì†¡"""
    try:
        import smtplib
        from email.mime.multipart import MIMEMultipart
        from email.mime.text import MIMEText

        print(f"ğŸ“§ [DEBUG] ëŒ€ëŸ‰ ë©”ì¼ ë°œì†¡ ìš”ì²­ ì‹œì‘")

        data = await request.json()
        print(f"ğŸ“§ [DEBUG] ë°›ì€ ë°ì´í„°: {data}")

        status_type = data.get("statusType")
        print(f"ğŸ“§ [DEBUG] statusType: {status_type}")

        if not status_type:
            print(f"ğŸ“§ [DEBUG] ìƒíƒœ íƒ€ì…ì´ ì—†ìŒ")
            raise HTTPException(status_code=400, detail="ìƒíƒœ íƒ€ì…ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ë©”ì¼ ì„¤ì • ì¡°íšŒ
        print(f"ğŸ“§ [DEBUG] ë©”ì¼ ì„¤ì • ì¡°íšŒ ì‹œì‘")
        mail_settings = await db.mail_settings.find_one({"_id": "default"})
        print(f"ğŸ“§ [DEBUG] ë©”ì¼ ì„¤ì • ì¡°íšŒ ê²°ê³¼: {mail_settings}")

        if not mail_settings:
            print(f"ğŸ“§ [DEBUG] ë©”ì¼ ì„¤ì •ì´ ì—†ìŒ")
            raise HTTPException(status_code=400, detail="ë©”ì¼ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ
        print(f"ğŸ“§ [DEBUG] ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ ì‹œì‘")
        mail_templates = await db.mail_templates.find_one({"_id": "default"})
        print(f"ğŸ“§ [DEBUG] ë©”ì¼ í…œí”Œë¦¿ ì¡°íšŒ ê²°ê³¼: {mail_templates}")

        if not mail_templates:
            print(f"ğŸ“§ [DEBUG] ë©”ì¼ í…œí”Œë¦¿ì´ ì—†ìŒ")
            raise HTTPException(status_code=400, detail="ë©”ì¼ í…œí”Œë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ì§€ì›ì ì¡°íšŒ
        print(f"ğŸ“§ [DEBUG] ì§€ì›ì ì¡°íšŒ ì‹œì‘ - statusType: {status_type}")

        if status_type == 'passed':
            # í•©ê²©ì (ì„œë¥˜í•©ê²©, ìµœì¢…í•©ê²©)
            print(f"ğŸ“§ [DEBUG] í•©ê²©ì ì¡°íšŒ ì¿¼ë¦¬ ì‹¤í–‰")
            applicants = await db.applicants.find({
                "status": {"$in": ["ì„œë¥˜í•©ê²©", "ìµœì¢…í•©ê²©"]}
            }).to_list(None)
            print(f"ğŸ“§ [DEBUG] í•©ê²©ì ì¡°íšŒ ê²°ê³¼: {len(applicants)}ëª…")
        elif status_type == 'document_passed':
            # ì„œë¥˜í•©ê²©ì
            print(f"ğŸ“§ [DEBUG] ì„œë¥˜í•©ê²©ì ì¡°íšŒ ì¿¼ë¦¬ ì‹¤í–‰")
            applicants = await db.applicants.find({
                "status": "ì„œë¥˜í•©ê²©"
            }).to_list(None)
            print(f"ğŸ“§ [DEBUG] ì„œë¥˜í•©ê²©ì ì¡°íšŒ ê²°ê³¼: {len(applicants)}ëª…")
        elif status_type == 'final_passed':
            # ìµœì¢…í•©ê²©ì
            print(f"ğŸ“§ [DEBUG] ìµœì¢…í•©ê²©ì ì¡°íšŒ ì¿¼ë¦¬ ì‹¤í–‰")
            applicants = await db.applicants.find({
                "status": "ìµœì¢…í•©ê²©"
            }).to_list(None)
            print(f"ğŸ“§ [DEBUG] ìµœì¢…í•©ê²©ì ì¡°íšŒ ê²°ê³¼: {len(applicants)}ëª…")
        elif status_type == 'rejected':
            # ë¶ˆí•©ê²©ì (ì„œë¥˜ë¶ˆí•©ê²©)
            print(f"ğŸ“§ [DEBUG] ë¶ˆí•©ê²©ì ì¡°íšŒ ì¿¼ë¦¬ ì‹¤í–‰")
            applicants = await db.applicants.find({
                "status": "ì„œë¥˜ë¶ˆí•©ê²©"
            }).to_list(None)
            print(f"ğŸ“§ [DEBUG] ë¶ˆí•©ê²©ì ì¡°íšŒ ê²°ê³¼: {len(applicants)}ëª…")
        elif status_type == 'document_rejected':
            # ì„œë¥˜ë¶ˆí•©ê²©ì
            print(f"ğŸ“§ [DEBUG] ì„œë¥˜ë¶ˆí•©ê²©ì ì¡°íšŒ ì¿¼ë¦¬ ì‹¤í–‰")
            applicants = await db.applicants.find({
                "status": "ì„œë¥˜ë¶ˆí•©ê²©"
            }).to_list(None)
            print(f"ğŸ“§ [DEBUG] ì„œë¥˜ë¶ˆí•©ê²©ì ì¡°íšŒ ê²°ê³¼: {len(applicants)}ëª…")
        else:
            print(f"ğŸ“§ [DEBUG] ì˜ëª»ëœ ìƒíƒœ íƒ€ì…: {status_type}")
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ìƒíƒœ íƒ€ì…ì…ë‹ˆë‹¤.")

        print(f"ğŸ“§ [DEBUG] ì¡°íšŒëœ ì§€ì›ì ëª©ë¡:")
        for i, applicant in enumerate(applicants[:5]):  # ì²˜ìŒ 5ëª…ë§Œ ì¶œë ¥
            print(f"  {i+1}. {applicant.get('name', 'Unknown')} - {applicant.get('email', 'No email')} - {applicant.get('status', 'No status')}")

        if not applicants:
            print(f"ğŸ“§ [DEBUG] ë°œì†¡í•  ì§€ì›ìê°€ ì—†ìŒ")
            return {
                "success": False,
                "message": "ë°œì†¡í•  ì§€ì›ìê°€ ì—†ìŠµë‹ˆë‹¤.",
                "total": 0,
                "success_count": 0,
                "failed_count": 0
            }

        # ë©”ì¼ í…œí”Œë¦¿ ì„ íƒ
        template = mail_templates.get(status_type, {})
        if not template:
            print(f"ğŸ“§ [DEBUG] {status_type} ìƒíƒœì— ëŒ€í•œ ë©”ì¼ í…œí”Œë¦¿ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ğŸ“§ [DEBUG] ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿: {list(mail_templates.keys())}")
            return {
                "success": False,
                "message": f"{status_type} ìƒíƒœì— ëŒ€í•œ ë©”ì¼ í…œí”Œë¦¿ì´ ì—†ìŠµë‹ˆë‹¤. /settings í˜ì´ì§€ì—ì„œ í…œí”Œë¦¿ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.",
                "total": 0,
                "success_count": 0,
                "failed_count": 0
            }

        success_count = 0
        failed_count = 0
        failed_emails = []

        for applicant in applicants:
            # ì§€ì›ì ì´ë©”ì¼ í™•ì¸
            email = applicant.get('email')
            if not email:
                failed_count += 1
                continue

            # ì±„ìš©ê³µê³  ì •ë³´ ì¡°íšŒ
            job_posting_id = applicant.get('job_posting_id')
            job_posting = {}
            if job_posting_id:
                job_posting = await db.job_postings.find_one({"_id": ObjectId(job_posting_id)}) or {}

            # ë©”ì¼ ë‚´ìš© í¬ë§·íŒ…
            try:
                content = template.get('content', '').format(
                    applicant_name=applicant.get('name', 'ì§€ì›ì'),
                    job_posting_title=job_posting.get('title', 'ì±„ìš©ê³µê³ '),
                    company_name=job_posting.get('company', 'íšŒì‚¬ëª…'),
                    position=applicant.get('position', 'ì§€ì› ì§ë¬´')
                )
            except Exception as e:
                print(f"ë©”ì¼ ë‚´ìš© í¬ë§·íŒ… ì‹¤íŒ¨: {e}")
                content = template.get('content', '')

            # ë©”ì¼ ê°ì²´ ìƒì„±
            msg = MIMEMultipart()
            msg['From'] = f"{mail_settings.get('senderName', '')} <{mail_settings.get('senderEmail')}>"
            msg['To'] = email
            msg['Subject'] = template.get('subject', 'ì•ˆë‚´ ë©”ì¼')
            msg.attach(MIMEText(content, 'plain', 'utf-8'))

            # SMTP ì„œë²„ ì—°ê²° ë° ë©”ì¼ ë°œì†¡
            try:
                smtp_port = mail_settings.get('smtpPort', 587)
                smtp_server = mail_settings.get('smtpServer', 'smtp.gmail.com')

                if smtp_port == 465:
                    with smtplib.SMTP_SSL(smtp_server, smtp_port) as server:
                        server.login(mail_settings.get('senderEmail'), mail_settings.get('senderPassword'))
                        server.send_message(msg)
                else:
                    with smtplib.SMTP(smtp_server, smtp_port) as server:
                        server.starttls()
                        server.login(mail_settings.get('senderEmail'), mail_settings.get('senderPassword'))
                        server.send_message(msg)

                success_count += 1
                print(f"âœ… {applicant.get('name', 'Unknown')} ({email}) - ë©”ì¼ ë°œì†¡ ì„±ê³µ")

            except Exception as e:
                failed_count += 1
                failed_emails.append(email)
                print(f"âŒ {applicant.get('name', 'Unknown')} ({email}) - ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

        # ê²°ê³¼ ë°˜í™˜
        result = {
            "success": True,
            "total": len(applicants),
            "success_count": success_count,
            "failed_count": failed_count,
            "failed_emails": failed_emails,
            "message": f"ë©”ì¼ ë°œì†¡ ì™„ë£Œ: {success_count}ê±´ ì„±ê³µ, {failed_count}ê±´ ì‹¤íŒ¨"
        }

        print(f"\nğŸ“Š ë©”ì¼ ë°œì†¡ ê²°ê³¼:")
        print(f"  - ì´ ëŒ€ìƒ: {len(applicants)}ëª…")
        print(f"  - ì„±ê³µ: {success_count}ê±´")
        print(f"  - ì‹¤íŒ¨: {failed_count}ê±´")

        return result

    except HTTPException:
        raise
    except Exception as e:
        print(f"ëŒ€ëŸ‰ ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ëŒ€ëŸ‰ ë©”ì¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ë¡œê¹… ì„¤ì • (ë²„í¼ ë¶„ë¦¬ ë¬¸ì œ í•´ê²°)
logging.basicConfig(
    level=logging.WARNING,
    format='%(levelname)s:%(name)s:%(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('server.log', encoding='utf-8', mode='a')
    ]
)

# ë¡œê¹… í•¸ë“¤ëŸ¬ ì„¤ì •
for handler in logging.root.handlers:
    handler.setFormatter(logging.Formatter('%(levelname)s:%(name)s:%(message)s'))

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
